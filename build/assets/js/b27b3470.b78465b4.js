"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[8276],{8038:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var o=t(4848),i=t(8453);const s={sidebar_position:1,title:"Chapter 6: Frontend - Humanoid Robot Development"},a="Chapter 6: Frontend - Humanoid Robot Development",r={id:"chapter-06/intro-frontend",title:"Chapter 6: Frontend - Humanoid Robot Development",description:"Learning Objectives",source:"@site/docs/chapter-06/01-intro-frontend.md",sourceDirName:"chapter-06",slug:"/chapter-06/intro-frontend",permalink:"/docs/chapter-06/intro-frontend",draft:!1,unlisted:!1,editUrl:"https://github.com/tabindaseher/Physical-AI-Humanoid-Robotics/edit/main/docs/chapter-06/01-intro-frontend.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"Chapter 6: Frontend - Humanoid Robot Development"},sidebar:"tutorialSidebar",previous:{title:"Chapter 5 Exercises",permalink:"/docs/chapter-05/exercises"},next:{title:"Chapter 6 Learning Outcomes",permalink:"/docs/chapter-06/learning-outcomes"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"6.1 Humanoid Robot Design Principles",id:"61-humanoid-robot-design-principles",level:2},{value:"Anthropomorphic Design Considerations",id:"anthropomorphic-design-considerations",level:3},{value:"Degrees of Freedom and Mobility",id:"degrees-of-freedom-and-mobility",level:3},{value:"Actuator Selection and Placement",id:"actuator-selection-and-placement",level:3},{value:"Structural Materials and Fabrication",id:"structural-materials-and-fabrication",level:3},{value:"6.2 Locomotion and Gait Control",id:"62-locomotion-and-gait-control",level:2},{value:"Bipedal Walking Mechanics",id:"bipedal-walking-mechanics",level:3},{value:"Zero Moment Point (ZMP) Control",id:"zero-moment-point-zmp-control",level:3},{value:"Gait Pattern Generation",id:"gait-pattern-generation",level:3},{value:"6.3 Manipulation and Dexterity",id:"63-manipulation-and-dexterity",level:2},{value:"Anthropomorphic Hands and Fingers",id:"anthropomorphic-hands-and-fingers",level:3},{value:"Grasp Planning and Execution",id:"grasp-planning-and-execution",level:3},{value:"Multi-limb Coordination",id:"multi-limb-coordination",level:3},{value:"6.4 Humanoid Control Architectures",id:"64-humanoid-control-architectures",level:2},{value:"Hierarchical Control Systems",id:"hierarchical-control-systems",level:3},{value:"Central Pattern Generators (CPGs)",id:"central-pattern-generators-cpgs",level:3},{value:"6.5 Safety and Emergency Systems",id:"65-safety-and-emergency-systems",level:2},{value:"Humanoid Safety Manager",id:"humanoid-safety-manager",level:3},{value:"6.6 Practical Example: Complete Humanoid System",id:"66-practical-example-complete-humanoid-system",level:2},{value:"6.7 Summary",id:"67-summary",level:2},{value:"6.8 Exercises",id:"68-exercises",level:2},{value:"Exercise 6.1: Bipedal Walking Simulation",id:"exercise-61-bipedal-walking-simulation",level:3},{value:"Exercise 6.2: Grasp Planning Algorithm",id:"exercise-62-grasp-planning-algorithm",level:3},{value:"Exercise 6.3: Multi-limb Coordination",id:"exercise-63-multi-limb-coordination",level:3},{value:"Exercise 6.4: Safety System Integration",id:"exercise-64-safety-system-integration",level:3},{value:"Exercise 6.5: Complete Humanoid Controller",id:"exercise-65-complete-humanoid-controller",level:3}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"chapter-6-frontend---humanoid-robot-development",children:"Chapter 6: Frontend - Humanoid Robot Development"}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"By the end of this chapter, you should be able to:"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Remember"}),": List the key components and design principles of humanoid robot development"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Understand"}),": Explain the biomechanics, dynamics, and control challenges of humanoid robots"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Apply"}),": Design and implement control systems for humanoid robot locomotion and manipulation"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Analyze"}),": Evaluate the gait stability and balance systems in humanoid robots"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Evaluate"}),": Compare different humanoid robot platforms and their capabilities"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Create"}),": Develop a complete humanoid robot subsystem with perception, control, and safety"]}),"\n",(0,o.jsx)(n.h2,{id:"61-humanoid-robot-design-principles",children:"6.1 Humanoid Robot Design Principles"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots are designed to mimic human form and function, which provides unique advantages and challenges in robotics. The human-like form factor enables interaction with human environments and tools, but also requires sophisticated control systems to replicate human capabilities."}),"\n",(0,o.jsx)(n.h3,{id:"anthropomorphic-design-considerations",children:"Anthropomorphic Design Considerations"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots incorporate human-like features that serve both functional and social purposes:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Bipedal Locomotion"}),": Two-legged walking capability similar to humans"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Upper Limb Manipulation"}),": Arms and hands designed for dexterous manipulation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensory Systems"}),": Vision, hearing, and tactile systems positioned similarly to humans"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Communication Interface"}),": Face and body language for human-robot interaction"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"degrees-of-freedom-and-mobility",children:"Degrees of Freedom and Mobility"}),"\n",(0,o.jsx)(n.p,{children:"The number and arrangement of joints significantly impact a humanoid robot's capabilities:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class HumanoidRobotConfig:\n    def __init__(self):\n        # Define joint configuration similar to human body\n        self.left_leg = {\n            'hip_yaw_pitch': {'range': (-45, 45), 'type': 'revolute'},\n            'hip_roll': {'range': (-20, 45), 'type': 'revolute'},\n            'hip_pitch': {'range': (-120, 30), 'type': 'revolute'},\n            'knee': {'range': (0, 135), 'type': 'revolute'},\n            'ankle_pitch': {'range': (-45, 45), 'type': 'revolute'},\n            'ankle_roll': {'range': (-20, 20), 'type': 'revolute'}\n        }\n        \n        self.right_leg = self._mirror_joints(self.left_leg)\n        \n        self.left_arm = {\n            'shoulder_pitch': {'range': (-120, 120), 'type': 'revolute'},\n            'shoulder_roll': {'range': (-90, 30), 'type': 'revolute'},\n            'shoulder_yaw': {'range': (-120, 120), 'type': 'revolute'},\n            'elbow': {'range': (0, 160), 'type': 'revolute'},\n            'wrist_yaw': {'range': (-120, 120), 'type': 'revolute'},\n            'wrist_pitch': {'range': (-90, 90), 'type': 'revolute'},\n            'wrist_roll': {'range': (-120, 120), 'type': 'revolute'}\n        }\n        \n        self.right_arm = self._mirror_joints(self.left_arm)\n        \n        self.torso = {\n            'waist_yaw': {'range': (-60, 60), 'type': 'revolute'},\n            'waist_pitch': {'range': (-30, 30), 'type': 'revolute'},\n            'waist_roll': {'range': (-30, 30), 'type': 'revolute'}\n        }\n        \n        self.head = {\n            'neck_yaw': {'range': (-120, 120), 'type': 'revolute'},\n            'neck_pitch': {'range': (-30, 60), 'type': 'revolute'},\n            'neck_roll': {'range': (-30, 30), 'type': 'revolute'}\n        }\n    \n    def _mirror_joints(self, joints):\n        \"\"\"Create mirror configuration for opposite side\"\"\"\n        mirrored = {}\n        for name, props in joints.items():\n            mirrored[name] = props.copy()\n        return mirrored\n    \n    def get_total_dof(self):\n        \"\"\"Calculate total degrees of freedom\"\"\"\n        total = 0\n        for limb in [self.left_leg, self.right_leg, self.left_arm, self.right_arm, \n                     self.torso, self.head]:\n            total += len(limb)\n        return total\n\n# Example usage\nrobot_config = HumanoidRobotConfig()\nprint(f\"Total DOF: {robot_config.get_total_dof()}\")\n"})}),"\n",(0,o.jsx)(n.h3,{id:"actuator-selection-and-placement",children:"Actuator Selection and Placement"}),"\n",(0,o.jsx)(n.p,{children:"Selecting appropriate actuators for humanoid robots requires balancing power, precision, and safety:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Servo Motors"}),": High precision, good for manipulation tasks"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Series Elastic Actuators (SEA)"}),": Compliant actuation for safe interaction"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pneumatic Muscles"}),": Human-like compliance and lightweight design"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Hydraulic Actuators"}),": High power-to-weight ratio for heavy lifting"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"structural-materials-and-fabrication",children:"Structural Materials and Fabrication"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots require materials that balance strength, weight, and safety:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Aluminum Alloys"}),": Lightweight with good strength-to-weight ratio"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Carbon Fiber"}),": Extremely lightweight with high strength"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Engineering Plastics"}),": Cost-effective for non-critical components"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Titanium"}),": High strength applications requiring corrosion resistance"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"62-locomotion-and-gait-control",children:"6.2 Locomotion and Gait Control"}),"\n",(0,o.jsx)(n.h3,{id:"bipedal-walking-mechanics",children:"Bipedal Walking Mechanics"}),"\n",(0,o.jsx)(n.p,{children:"Bipedal walking presents unique challenges due to the need for dynamic balance:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Single Support Phase"}),": One foot in contact with ground"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Double Support Phase"}),": Both feet in contact with ground"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Swing Phase"}),": Leg moves forward without ground contact"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Balance Control"}),": Maintaining center of mass within support polygon"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom scipy import integrate\nimport matplotlib.pyplot as plt\n\nclass BipedalWalker:\n    def __init__(self, mass=70, leg_length=0.9, gravity=9.81):\n        self.mass = mass  # kg\n        self.leg_length = leg_length  # m\n        self.gravity = gravity  # m/s^2\n        \n        # Walking parameters\n        self.step_length = 0.3  # m\n        self.step_height = 0.1  # m\n        self.gait_cycle_time = 1.0  # s\n        \n        # State variables\n        self.x = 0.0  # x position\n        self.y = 0.0  # y position (lateral movement)\n        self.z = leg_length  # z position (height)\n        self.omega = 0.0  # angular velocity\n        \n        # Control parameters\n        self.com_height = 0.85  # Center of mass height\n        self.zmp_x = 0.0  # Zero Moment Point x-coordinate\n        self.zmp_y = 0.0  # Zero Moment Point y-coordinate\n        \n    def inverted_pendulum_model(self, state, t):\n        """\n        Inverted pendulum model for bipedal walking\n        state = [x, y, z, dx, dy, dz, theta_x, theta_y, omega_x, omega_y]\n        """\n        x, y, z, dx, dy, dz, theta_x, theta_y, omega_x, omega_y = state\n        \n        # Simplified inverted pendulum dynamics\n        x_dd = self.gravity / (z - self.com_height) * theta_x\n        y_dd = self.gravity / (z - self.com_height) * theta_y\n        \n        # Angular velocity derivatives\n        theta_x_d = omega_x\n        theta_y_d = omega_y\n        \n        return [dx, dy, dz, x_dd, y_dd, 0, theta_x_d, theta_y_d, 0, 0]\n    \n    def compute_zmp(self, x, y, z, dx, dy, dz):\n        """\n        Compute Zero Moment Point (ZMP) for balance control\n        """\n        # ZMP calculation based on center of mass and ground reaction forces\n        zmp_x = x - (z - self.com_height) / self.gravity * dx\n        zmp_y = y - (z - self.com_height) / self.gravity * dy\n        \n        return zmp_x, zmp_y\n    \n    def generate_com_trajectory(self, start_pos, goal_pos, duration):\n        """\n        Generate Center of Mass trajectory for walking\n        """\n        # Simple 5th order polynomial trajectory\n        t = np.linspace(0, duration, int(duration * 100))  # 100 Hz sampling\n        \n        # Generate trajectory for each axis\n        x_traj = np.linspace(start_pos[0], goal_pos[0], len(t))\n        y_traj = np.full_like(t, self.com_height)  # Keep CoM at constant height\n        z_traj = np.full_like(t, self.com_height)  # Constant height\n        \n        # Add small lateral movement for balance\n        y_traj += 0.05 * np.sin(2 * np.pi * t / duration)\n        \n        return t, np.column_stack([x_traj, y_traj, z_traj])\n    \n    def step_pattern_generator(self, step_length, step_height, step_time):\n        """\n        Generate step pattern for walking gait\n        """\n        t = np.linspace(0, step_time, int(step_time * 100))\n        \n        # Swing leg trajectory\n        x_swing = step_length * (1 - np.cos(np.pi * t / step_time)) / 2\n        z_swing = step_height * np.sin(np.pi * t / step_time)\n        \n        # Support leg stays relatively constant but with small adjustments\n        x_support = np.full_like(t, step_length / 2)  # Average position\n        z_support = np.full_like(t, 0)  # Ground level\n        \n        return {\n            \'swing_leg\': np.column_stack([x_swing, np.zeros_like(x_swing), z_swing]),\n            \'support_leg\': np.column_stack([x_support, np.zeros_like(x_support), z_support])\n        }\n\nclass WalkingController:\n    def __init__(self):\n        self.biped_model = BipedalWalker()\n        self.zmp_reference = np.array([0.0, 0.0])\n        self.com_reference = np.array([0.0, 0.0, 0.85])\n        \n        # Controller gains\n        self.k_p = 10.0  # Proportional gain\n        self.k_d = 2.0   # Derivative gain\n        self.k_i = 1.0   # Integral gain\n        \n    def zmp_controller(self, current_zmp, dt):\n        """ZMP-based balance controller"""\n        error = self.zmp_reference - current_zmp\n        self.integral_error += error * dt\n        \n        # PID control for balance\n        control_output = self.k_p * error + self.k_i * self.integral_error\n        return control_output\n    \n    def compute_foot_placement(self, com_state, target_velocity):\n        """Compute optimal foot placement for balance"""\n        # Simple model for foot placement based on inverted pendulum\n        # Calculate where to place foot to maintain balance\n        com_x, com_y, com_z = com_state\n        com_x_dot, com_y_dot = target_velocity[:2]\n        \n        # Time to foot placement\n        support_time = 0.8  # seconds\n        \n        # Predict where CoM will be\n        predicted_x = com_x + com_x_dot * support_time\n        predicted_y = com_y + com_y_dot * support_time\n        \n        # Add safety margin\n        foot_x = predicted_x + 0.1  # Small forward margin\n        foot_y = com_y + 0.0  # Stay in line with CoM y\n        \n        return np.array([foot_x, foot_y, 0.0])\n'})}),"\n",(0,o.jsx)(n.h3,{id:"zero-moment-point-zmp-control",children:"Zero Moment Point (ZMP) Control"}),"\n",(0,o.jsx)(n.p,{children:"ZMP control is fundamental to humanoid balance during walking:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class ZMPController:\n    def __init__(self, robot_mass, com_height, gravity=9.81):\n        self.mass = robot_mass\n        self.com_height = com_height\n        self.gravity = gravity\n        self.integral_error = np.zeros(2)\n        \n        # Controller parameters\n        self.kp = 100.0  # Proportional gain\n        self.kd = 10.0   # Derivative gain \n        self.ki = 1.0    # Integral gain\n        \n    def compute_zmp(self, com_pos, com_vel, com_acc, cop_pos):\n        """\n        Compute Zero Moment Point based on CoM and CoP information\n        """\n        # ZMP_x = CoM_x - (CoM_z - h) / g * CoM_acc_x\n        # ZMP_y = CoM_y - (CoM_z - h) / g * CoM_acc_y\n        \n        zmp = np.array([\n            com_pos[0] - (com_pos[2] - self.com_height) / self.gravity * com_acc[0],\n            com_pos[1] - (com_pos[2] - self.com_height) / self.gravity * com_acc[1]\n        ])\n        \n        return zmp\n    \n    def balance_control(self, current_zmp, reference_zmp, dt):\n        """\n        Compute control forces to maintain balance\n        """\n        # Calculate error\n        error = reference_zmp - current_zmp\n        \n        # Update integral term\n        self.integral_error += error * dt\n        \n        # Compute control output (PID)\n        control_output = (\n            self.kp * error + \n            self.kd * (error - self.previous_error) / dt + \n            self.ki * self.integral_error\n        )\n        \n        self.previous_error = error.copy()\n        \n        return control_output\n    \n    def update_reference_zmp(self, com_pos, target_pos, stiffness=1.0):\n        """\n        Update reference ZMP based on desired center of mass position\n        """\n        # Simple spring-mass tracking of desired position\n        pos_error = target_pos - com_pos[:2]\n        reference_zmp = target_pos - stiffness * pos_error\n        \n        # Keep reference within support polygon\n        reference_zmp = self.constrain_to_support_polygon(reference_zmp)\n        \n        return reference_zmp\n    \n    def constrain_to_support_polygon(self, zmp):\n        """\n        Constrain ZMP to be within the convex hull of foot support points\n        """\n        # For a simple case with rectangular feet\n        foot_width = 0.1  # meters\n        foot_length = 0.15  # meters\n        \n        # This would be more complex in a real implementation\n        constrained_zmp = np.clip(zmp, [-foot_width/2, -foot_length/2], \n                                [foot_width/2, foot_length/2])\n        \n        return constrained_zmp\n'})}),"\n",(0,o.jsx)(n.h3,{id:"gait-pattern-generation",children:"Gait Pattern Generation"}),"\n",(0,o.jsx)(n.p,{children:"Creating stable walking patterns requires sophisticated trajectory planning:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class GaitPatternGenerator:\n    def __init__(self, step_length=0.3, step_height=0.1, step_time=0.8):\n        self.step_length = step_length\n        self.step_height = step_height\n        self.step_time = step_time\n        \n        # Walking parameters\n        self.stride_length = 2 * step_length  # Distance between foot placements\n        self.walking_speed = self.stride_length / step_time  # m/s\n        \n    def generate_walk_trajectory(self, num_steps, start_pos=np.array([0, 0, 0])):\n        """\n        Generate complete walking trajectory for specified number of steps\n        """\n        trajectory = []\n        time_points = []\n        \n        current_pos = start_pos.copy()\n        \n        for step in range(num_steps):\n            # Generate single step trajectory\n            step_trajectory, step_times = self.generate_single_step(\n                current_pos, step % 2  # Alternate between left/right foot\n            )\n            \n            # Update current position for next step\n            current_pos[0] += self.stride_length / 2  # Move forward by half a stride\n            \n            trajectory.extend(step_trajectory)\n            time_points.extend(step_times)\n        \n        return np.array(trajectory), np.array(time_points)\n    \n    def generate_single_step(self, start_pos, foot_index):\n        """\n        Generate trajectory for a single step (either left or right foot)\n        foot_index: 0 for left foot, 1 for right foot\n        """\n        t = np.linspace(0, self.step_time, int(self.step_time * 100))  # 100 Hz\n        \n        # Swing foot trajectory (parabolic for smooth movement)\n        x_swing = start_pos[0] + self.step_length * (1 - np.cos(np.pi * t / self.step_time)) / 2\n        y_swing = start_pos[1] + (-1)**foot_index * 0.15  # Offset for left/right foot\n        z_swing = start_pos[2] + self.step_height * np.sin(np.pi * t / self.step_time)\n        \n        # Support foot trajectory (minimal movement)\n        x_support = start_pos[0] * np.ones_like(t)\n        y_support = start_pos[1] + (-1)**(1-foot_index) * 0.15  # Opposite foot position\n        z_support = start_pos[2] * np.ones_like(t)  # Ground level\n        \n        step_trajectory = []\n        for i in range(len(t)):\n            if foot_index == 0:  # Left foot is swing foot\n                step_trajectory.append([\n                    x_swing[i], y_swing[i], z_swing[i],  # Left foot\n                    x_support[i], y_support[i], z_support[i]  # Right foot\n                ])\n            else:  # Right foot is swing foot\n                step_trajectory.append([\n                    x_support[i], y_support[i], z_support[i],  # Left foot\n                    x_swing[i], y_swing[i], z_swing[i]  # Right foot\n                ])\n        \n        return step_trajectory, t.tolist()\n    \n    def adjust_for_obstacles(self, trajectory, obstacle_positions):\n        """\n        Adjust gait pattern to avoid obstacles\n        """\n        # This would implement obstacle avoidance during walking\n        # For now, a simplified version\n        adjusted_trajectory = trajectory.copy()\n        \n        for i, pos in enumerate(adjusted_trajectory):\n            for obs_pos in obstacle_positions:\n                if self.distance_to_obstacle(pos[:2], obs_pos[:2]) < 0.3:  # 30cm clearance\n                    # Adjust step to go around obstacle\n                    adjusted_trajectory[i][0] += 0.1  # Move slightly to the side\n                    adjusted_trajectory[i][3] += 0.1  # Move support foot too\n        \n        return adjusted_trajectory\n    \n    def distance_to_obstacle(self, point1, point2):\n        """Calculate distance between two 2D points"""\n        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"63-manipulation-and-dexterity",children:"6.3 Manipulation and Dexterity"}),"\n",(0,o.jsx)(n.h3,{id:"anthropomorphic-hands-and-fingers",children:"Anthropomorphic Hands and Fingers"}),"\n",(0,o.jsx)(n.p,{children:"Creating dexterous hands remains one of the greatest challenges in humanoid robotics:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Underactuation"}),": Using fewer actuators than degrees of freedom"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Tendon-driven systems"}),": Mimicking human muscle-tendon systems"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Compliant mechanisms"}),": Built-in compliance for safe interaction"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Tactile sensing"}),": Feedback for grasp stability and object properties"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"grasp-planning-and-execution",children:"Grasp Planning and Execution"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import open3d as o3d\nfrom scipy.spatial.distance import cdist\nimport numpy as np\n\nclass GraspPlanner:\n    def __init__(self):\n        # Grasp primitive types\n        self.grasp_types = [\n            \'precision_pinch\', \n            \'power_grasp\', \n            \'spherical_grasp\',\n            \'circular_grasp\',\n            \'lateral_grasp\'\n        ]\n        \n        # Hand kinematics (simplified)\n        self.finger_lengths = [0.04, 0.035, 0.03]  # Three segments per finger\n        self.hand_width = 0.08  # Maximum hand opening\n        self.finger_count = 5\n        \n    def find_grasp_points(self, object_mesh):\n        """\n        Find potential grasp points on object surface\n        """\n        # Sample points on object surface\n        surface_points = self.sample_surface_points(object_mesh)\n        \n        # Analyze object geometry to find suitable grasp locations\n        grasp_candidates = []\n        \n        for point in surface_points:\n            # Check for suitable grasp direction at this point\n            normal = self.estimate_surface_normal(object_mesh, point)\n            \n            # Calculate approach direction (orthogonal to normal)\n            approach_dirs = self.generate_approach_directions(normal)\n            \n            for approach_dir in approach_dirs:\n                if self.is_stable_grasp(object_mesh, point, approach_dir):\n                    grasp_candidates.append({\n                        \'position\': point,\n                        \'normal\': normal,\n                        \'approach\': approach_dir,\n                        \'quality\': self.evaluate_grasp_quality(object_mesh, point, approach_dir)\n                    })\n        \n        # Sort candidates by quality score\n        grasp_candidates.sort(key=lambda x: x[\'quality\'], reverse=True)\n        \n        return grasp_candidates\n    \n    def sample_surface_points(self, mesh, num_points=100):\n        """Sample points on mesh surface"""\n        pcd = mesh.sample_points_uniformly(number_of_points=num_points)\n        return np.asarray(pcd.points)\n    \n    def estimate_surface_normal(self, mesh, point):\n        """Estimate surface normal at a point"""\n        # In practice, this would use mesh normals or point cloud analysis\n        # For this example, we\'ll return a dummy normal\n        return np.array([0, 0, 1])  # Default upward normal\n    \n    def generate_approach_directions(self, normal):\n        """Generate possible approach directions orthogonal to surface normal"""\n        # Generate directions perpendicular to surface normal\n        # This is a simplified implementation\n        directions = []\n        \n        # Create rotation matrix to get orthogonal directions\n        z_axis = normal / np.linalg.norm(normal)\n        \n        # Find one orthogonal vector\n        if abs(z_axis[2]) < 0.9:\n            x_axis = np.cross(z_axis, [0, 0, 1])\n        else:\n            x_axis = np.cross(z_axis, [1, 0, 0])\n        \n        x_axis = x_axis / np.linalg.norm(x_axis)\n        y_axis = np.cross(z_axis, x_axis)\n        \n        # Generate multiple approach directions\n        for angle in np.linspace(0, 2*np.pi, 8):\n            direction = np.cos(angle) * x_axis + np.sin(angle) * y_axis\n            directions.append(direction)\n        \n        return directions\n    \n    def is_stable_grasp(self, object_mesh, point, approach_dir):\n        """Check if a grasp is geometrically stable"""\n        # Check if approach direction allows for a stable grip\n        # This would involve checking for adequate contact areas\n        # and force closure properties\n        \n        # Simplified check: ensure approach direction doesn\'t intersect\n        # with object in a way that prevents grasping\n        grasp_length = 0.03  # Typical grasp depth\n        grasp_end = point - grasp_length * approach_dir / np.linalg.norm(approach_dir)\n        \n        # Check if line from point to grasp_end intersects object\n        # (indicating grasp would be blocked)\n        intersection = self.check_line_mesh_intersection(\n            point, grasp_end, object_mesh\n        )\n        \n        return not intersection\n    \n    def check_line_mesh_intersection(self, start, end, mesh):\n        """Check if line intersects with mesh"""\n        # Simplified intersection check\n        # In practice, this would use ray-casting or geometric algorithms\n        return False\n    \n    def evaluate_grasp_quality(self, object_mesh, point, approach_dir):\n        """Evaluate the quality of a potential grasp"""\n        # Consider factors like:\n        # - Surface curvature at contact point\n        # - Object size relative to hand\n        # - Approach accessibility\n        # - Stability of grasp\n        \n        quality = 0.0\n        \n        # Curvature consideration (flatter surfaces are better for grasping)\n        curvature = self.estimate_curvature(object_mesh, point)\n        quality += max(0, 1.0 - abs(curvature) * 10)  # Lower curvature = better\n        \n        # Size consideration (object should fit in hand)\n        object_size = self.estimate_object_size(object_mesh)\n        if object_size < self.hand_width:\n            quality += 0.3\n        else:\n            quality += max(0, 0.3 * (self.hand_width / object_size))\n        \n        # Approach accessibility\n        accessibility = self.evaluate_approach_accessibility(point, approach_dir)\n        quality += accessibility * 0.4\n        \n        return min(quality, 1.0)\n    \n    def estimate_curvature(self, mesh, point):\n        """Estimate surface curvature at a point"""\n        # Simplified curvature estimation\n        return 0.0  # For now, assume flat surface\n    \n    def estimate_object_size(self, mesh):\n        """Estimate characteristic size of object"""\n        bounds = mesh.get_axis_aligned_bounding_box()\n        dims = bounds.get_extent()\n        return max(dims)\n    \n    def evaluate_approach_accessibility(self, point, approach_dir):\n        """Evaluate how accessible the approach is"""\n        # Consider obstacles, robot configuration, etc.\n        return 1.0  # Assume fully accessible for this example\n    \n    def plan_hand_trajectory(self, grasp_pose, pre_grasp_offset=0.05):\n        """\n        Plan trajectory to move hand to grasp position\n        """\n        # Calculate pre-grasp pose (approach from safe distance)\n        pre_grasp_pose = grasp_pose.copy()\n        pre_grasp_pose[:3] += pre_grasp_offset * grasp_pose[3:6]  # Move along approach vector\n        \n        # Plan trajectory through joint space\n        trajectory = self.interpolate_trajectory(pre_grasp_pose, grasp_pose)\n        \n        return trajectory\n    \n    def interpolate_trajectory(self, start_pose, end_pose, steps=50):\n        """Interpolate between two poses"""\n        trajectory = []\n        \n        for i in range(steps + 1):\n            t = i / steps\n            pose = (1 - t) * start_pose + t * end_pose\n            trajectory.append(pose)\n        \n        return trajectory\n\nclass HandController:\n    def __init__(self):\n        self.finger_positions = np.zeros(5)  # 5 fingers\n        self.finger_velocities = np.zeros(5)\n        self.finger_forces = np.zeros(5)\n        \n        # Grasp parameters\n        self.grasp_force_limits = [10, 10, 10, 10, 10]  # N\n        self.finger_range = [0, 90]  # degrees\n        \n    def execute_grasp(self, grasp_type, force_multiplier=1.0):\n        """Execute a specific type of grasp"""\n        if grasp_type == \'precision_pinch\':\n            # Move thumb and index finger together\n            self.finger_positions[0] = 60  # Thumb\n            self.finger_positions[1] = 60  # Index finger\n            # Keep other fingers in neutral position\n            self.finger_positions[2:] = 10  # Other fingers slightly curled\n            \n        elif grasp_type == \'power_grasp\':\n            # Close all fingers for power grasp\n            self.finger_positions = np.full(5, 80)  # Close all fingers\n            \n        elif grasp_type == \'cylindrical_grasp\':\n            # Grasp cylindrical objects\n            self.finger_positions[0] = 70  # Thumb wraps around\n            self.finger_positions[1:] = 60  # Other fingers close on opposite side\n            \n        # Apply force proportional to grasp type requirements\n        self.finger_forces = self.calculate_grasp_forces(grasp_type, force_multiplier)\n        \n        return self.finger_positions.copy(), self.finger_forces.copy()\n    \n    def calculate_grasp_forces(self, grasp_type, force_multiplier):\n        """Calculate appropriate grasp forces for different grasp types"""\n        base_forces = {\n            \'precision_pinch\': [5, 5, 1, 1, 1],\n            \'power_grasp\': [8, 8, 8, 8, 8],\n            \'cylindrical_grasp\': [6, 8, 8, 8, 8],\n            \'spherical_grasp\': [7, 7, 7, 7, 7],\n            \'lateral_grasp\': [10, 2, 1, 1, 1]\n        }\n        \n        forces = np.array(base_forces.get(grasp_type, [5, 5, 5, 5, 5]))\n        forces *= force_multiplier\n        \n        # Ensure forces are within limits\n        forces = np.clip(forces, 0, self.grasp_force_limits)\n        \n        return forces\n    \n    def adjust_grasp(self, tactile_feedback):\n        """\n        Adjust grasp based on tactile feedback\n        tactile_feedback: array with pressure info from tactile sensors\n        """\n        # Simple adjustment algorithm\n        if np.any(tactile_feedback > 0.8 * self.grasp_force_limits):\n            # Too much force detected, reduce slightly\n            self.finger_forces *= 0.95\n        elif np.any(tactile_feedback < 0.2 * self.grasp_force_limits):\n            # Not enough force for secure grasp, increase slightly\n            self.finger_forces *= 1.02\n            # Limit maximum force\n            self.finger_forces = np.clip(self.finger_forces, 0, self.grasp_force_limits)\n        \n        return self.finger_forces.copy()\n'})}),"\n",(0,o.jsx)(n.h3,{id:"multi-limb-coordination",children:"Multi-limb Coordination"}),"\n",(0,o.jsx)(n.p,{children:"Coordinating multiple limbs in humanoid robots requires sophisticated control:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"class MultiLimbCoordinator:\n    def __init__(self):\n        # Define limb coordination priorities\n        self.limb_priorities = {\n            'right_arm': 1,\n            'left_arm': 2, \n            'right_leg': 3,\n            'left_leg': 4\n        }\n        \n        # Task coordination system\n        self.active_tasks = {}\n        self.task_dependencies = {}\n        \n    def coordinate_task_execution(self, tasks):\n        \"\"\"\n        Coordinate execution of multiple tasks across different limbs\n        \"\"\"\n        # Resolve task conflicts and dependencies\n        resolved_tasks = self.resolve_conflicts(tasks)\n        \n        # Schedule task execution\n        execution_plan = self.schedule_tasks(resolved_tasks)\n        \n        return execution_plan\n    \n    def resolve_conflicts(self, tasks):\n        \"\"\"Resolve conflicts between simultaneous tasks\"\"\"\n        resolved_tasks = {}\n        \n        for limb, task in tasks.items():\n            conflict = self.check_task_conflict(limb, task)\n            if conflict:\n                # Resolve conflict based on priority\n                if self.limb_priorities[limb] < self.limb_priorities[conflict['conflicting_limb']]:\n                    # This limb has higher priority, adjust other task\n                    resolved_tasks[conflict['conflicting_limb']] = self.adjust_task(\n                        tasks[conflict['conflicting_limb']]\n                    )\n                else:\n                    # Lower priority task needs adjustment\n                    resolved_tasks[limb] = self.adjust_task(task)\n            else:\n                resolved_tasks[limb] = task\n        \n        return resolved_tasks\n    \n    def check_task_conflict(self, limb, task):\n        \"\"\"Check if a task conflicts with other active tasks\"\"\"\n        # For now, a simple check for collision in workspace\n        # In practice, this would check for workspace, timing, and priority conflicts\n        return None\n    \n    def adjust_task(self, original_task):\n        \"\"\"Adjust task to avoid conflicts\"\"\"\n        # Create a modified version of the task that avoids conflicts\n        adjusted_task = original_task.copy()\n        # Add delays, modify parameters, etc.\n        return adjusted_task\n    \n    def schedule_tasks(self, resolved_tasks):\n        \"\"\"Schedule tasks for execution across different limbs\"\"\"\n        # Create temporal schedule for task execution\n        schedule = {}\n        \n        for limb, task in resolved_tasks.items():\n            # Assign execution time based on task requirements\n            schedule[limb] = {\n                'task': task,\n                'start_time': self.calculate_start_time(task),\n                'duration': self.calculate_duration(task),\n                'priority': self.limb_priorities[limb]\n            }\n        \n        # Sort by start time and priority\n        sorted_schedule = sorted(schedule.items(), \n                               key=lambda x: (x[1]['start_time'], x[1]['priority']))\n        \n        return sorted_schedule\n\nclass HumanoidMotionController:\n    def __init__(self):\n        self.walking_controller = WalkingController()\n        self.grasp_planner = GraspPlanner()\n        self.multi_limb_coordinator = MultiLimbCoordinator()\n        self.safety_manager = HumanoidSafetyManager()\n        \n    def execute_complex_task(self, task_description):\n        \"\"\"\n        Execute complex tasks that involve multiple limbs and modalities\n        \"\"\"\n        # Parse high-level task into component actions\n        subtasks = self.parse_task(task_description)\n        \n        # Coordinate execution across different limbs\n        execution_plan = self.multi_limb_coordinator.coordinate_task_execution(subtasks)\n        \n        # Execute each component while maintaining safety\n        for limb, task_info in execution_plan:\n            if self.safety_manager.is_safe_to_execute(task_info['task']):\n                # Execute the task component\n                result = self.execute_task_component(limb, task_info['task'])\n                \n                # Monitor execution for safety\n                self.safety_manager.monitor_execution(result)\n            else:\n                # Safety check failed, handle accordingly\n                self.safety_manager.trigger_safety_protocol()\n                break\n        \n        return execution_plan\n    \n    def parse_task(self, task_description):\n        \"\"\"Parse natural language task into component actions\"\"\"\n        # This would involve NLP processing to extract task components\n        # For example: \"Walk to the table and pick up the red cup\" \n        # would be parsed into walking and grasping subtasks\n        subtasks = {}\n        \n        # Simplified parsing\n        if 'walk' in task_description.lower():\n            subtasks['right_leg'] = {'type': 'walking', 'destination': 'table'}\n        if 'pick' in task_description.lower() or 'grasp' in task_description.lower():\n            subtasks['right_arm'] = {'type': 'grasping', 'object': 'red cup'}\n            \n        return subtasks\n    \n    def execute_task_component(self, limb, task):\n        \"\"\"Execute a specific task component with the specified limb\"\"\"\n        if task['type'] == 'walking':\n            # Execute walking subtask\n            destination = task['destination']\n            # Implementation for walking to destination\n            pass\n        elif task['type'] == 'grasping':\n            # Execute grasping subtask\n            target_object = task['object']\n            # Implementation for grasping object\n            pass\n        \n        return {'status': 'complete', 'limb': limb}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"64-humanoid-control-architectures",children:"6.4 Humanoid Control Architectures"}),"\n",(0,o.jsx)(n.h3,{id:"hierarchical-control-systems",children:"Hierarchical Control Systems"}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots require control systems at multiple levels:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"High-level Planning"}),": Task planning and sequencing"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Mid-level Control"}),": Trajectory generation and coordination"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Low-level Control"}),": Joint servo control and feedback"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Safety Systems"}),": Emergency stops and collision avoidance"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"central-pattern-generators-cpgs",children:"Central Pattern Generators (CPGs)"}),"\n",(0,o.jsx)(n.p,{children:"CPGs provide rhythmic patterns for locomotion:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class CentralPatternGenerator:\n    def __init__(self, dt=0.01):\n        self.dt = dt\n        self.oscillators = []\n        self.connection_weights = []\n        self.outputs = []\n        \n    def add_oscillator(self, frequency, phase, amplitude):\n        """Add an oscillator to the CPG network"""\n        oscillator = {\n            \'frequency\': frequency,\n            \'phase\': phase,\n            \'amplitude\': amplitude,\n            \'state\': 0.0  # Current state (typically an angle)\n        }\n        self.oscillators.append(oscillator)\n        self.outputs.append(0.0)\n        \n    def connect_oscillators(self, i, j, weight):\n        """Connect two oscillators with specified weight"""\n        if len(self.connection_weights) <= i:\n            self.connection_weights.extend([[] for _ in range(i - len(self.connection_weights) + 1)])\n        while len(self.connection_weights[i]) <= j:\n            self.connection_weights[i].append(0.0)\n        self.connection_weights[i][j] = weight\n        \n    def step(self):\n        """Update all oscillators for one time step"""\n        for i, osc in enumerate(self.oscillators):\n            # Update oscillator state based on dynamics\n            # This is a simplified version; real CPGs use more complex dynamics\n            input_sum = 0.0\n            \n            # Add inputs from connected oscillators\n            if i < len(self.connection_weights):\n                for j, weight in enumerate(self.connection_weights[i]):\n                    if j < len(self.oscillators):\n                        input_sum += weight * np.sin(self.oscillators[j][\'state\'] - osc[\'state\'])\n            \n            # Update state with frequency and input\n            dstate_dt = 2 * np.pi * osc[\'frequency\'] + input_sum\n            osc[\'state\'] += dstate_dt * self.dt\n            \n            # Calculate output\n            self.outputs[i] = osc[\'amplitude\'] * np.sin(osc[\'state\'] + osc[\'phase\'])\n    \n    def get_outputs(self):\n        """Get current outputs from all oscillators"""\n        return self.outputs.copy()\n\nclass LocomotionCPG:\n    def __init__(self):\n        # Initialize CPG for bipedal locomotion\n        self.cpg = CentralPatternGenerator(dt=0.01)\n        \n        # Add oscillators for different joints\n        # Left leg oscillators\n        self.cpg.add_oscillator(frequency=1.0, phase=0.0, amplitude=1.0)  # Left hip\n        self.cpg.add_oscillator(frequency=1.0, phase=np.pi, amplitude=1.0)  # Right hip (anti-phase)\n        self.cpg.add_oscillator(frequency=1.0, phase=0.0, amplitude=0.5)   # Left knee\n        self.cpg.add_oscillator(frequency=1.0, phase=np.pi, amplitude=0.5)  # Right knee\n        \n        # Connect oscillators for coordinated movement\n        self.cpg.connect_oscillators(0, 1, -1.0)  # Left-right hip coupling\n        self.cpg.connect_oscillators(2, 3, -1.0)  # Left-right knee coupling\n        self.cpg.connect_oscillators(0, 2, 0.5)   # Hip-knee coupling\n        self.cpg.connect_oscillators(1, 3, 0.5)   # Hip-knee coupling (other side)\n        \n        # Parameters for gait adjustment\n        self.step_frequency = 1.0\n        self.step_amplitude = 1.0\n    \n    def update_gait_parameters(self, new_frequency, new_amplitude):\n        """Update gait parameters"""\n        self.step_frequency = new_frequency\n        self.step_amplitude = new_amplitude\n        \n        # Update oscillator frequencies and amplitudes\n        for i, osc in enumerate(self.cpg.oscillators):\n            osc[\'frequency\'] = new_frequency\n            osc[\'amplitude\'] = new_amplitude * osc[\'amplitude\'] / 1.0  # Maintain relative amplitudes\n    \n    def get_leg_commands(self):\n        """Get joint commands for both legs"""\n        outputs = self.cpg.get_outputs()\n        \n        # Map CPG outputs to actual joint angles\n        left_hip_cmd = outputs[0] if len(outputs) > 0 else 0.0\n        right_hip_cmd = outputs[1] if len(outputs) > 1 else 0.0\n        left_knee_cmd = outputs[2] if len(outputs) > 2 else 0.0\n        right_knee_cmd = outputs[3] if len(outputs) > 3 else 0.0\n        \n        commands = {\n            \'left_leg\': [left_hip_cmd, left_knee_cmd],\n            \'right_leg\': [right_hip_cmd, right_knee_cmd]\n        }\n        \n        self.cpg.step()  # Update CPG for next time step\n        \n        return commands\n'})}),"\n",(0,o.jsx)(n.h2,{id:"65-safety-and-emergency-systems",children:"6.5 Safety and Emergency Systems"}),"\n",(0,o.jsx)(n.p,{children:"Safety is paramount in humanoid robot development due to their human-like form factor and interaction potential."}),"\n",(0,o.jsx)(n.h3,{id:"humanoid-safety-manager",children:"Humanoid Safety Manager"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class HumanoidSafetyManager:\n    def __init__(self):\n        # Safety boundaries\n        self.joint_limits = {\n            \'hip_pitch\': (-120, 30),\n            \'knee\': (0, 135),\n            \'ankle_pitch\': (-45, 45),\n            \'shoulder_pitch\': (-120, 120),\n            \'elbow\': (0, 160)\n        }\n        \n        self.workspace_limits = {\n            \'x\': (-1.0, 1.0),\n            \'y\': (-1.0, 1.0),\n            \'z\': (0.1, 2.0)\n        }\n        \n        self.force_limits = {\n            \'gripper_force\': 50.0,  # N\n            \'collision_force\': 100.0  # N\n        }\n        \n        # Emergency systems\n        self.emergency_stop = False\n        self.fall_detected = False\n        self.over_force_detected = False\n        \n        # Safety monitoring\n        self.safety_monitoring_active = True\n        \n    def validate_command(self, joint_angles, cartesian_pos, forces):\n        """Validate robot commands against safety limits"""\n        safety_violations = []\n        \n        # Check joint limits\n        for joint_name, angle in joint_angles.items():\n            if joint_name in self.joint_limits:\n                min_limit, max_limit = self.joint_limits[joint_name]\n                if angle < min_limit or angle > max_limit:\n                    safety_violations.append(f"Joint {joint_name} out of limits: {angle} not in [{min_limit}, {max_limit}]")\n        \n        # Check workspace limits\n        if (cartesian_pos[0] < self.workspace_limits[\'x\'][0] or \n            cartesian_pos[0] > self.workspace_limits[\'x\'][1]):\n            safety_violations.append(f"X position {cartesian_pos[0]} outside limits")\n        \n        if (cartesian_pos[1] < self.workspace_limits[\'y\'][0] or \n            cartesian_pos[1] > self.workspace_limits[\'y\'][1]):\n            safety_violations.append(f"Y position {cartesian_pos[1]} outside limits")\n        \n        if (cartesian_pos[2] < self.workspace_limits[\'z\'][0] or \n            cartesian_pos[2] > self.workspace_limits[\'z\'][1]):\n            safety_violations.append(f"Z position {cartesian_pos[2]} outside limits")\n        \n        # Check force limits\n        for force_type, force_value in forces.items():\n            if force_type in self.force_limits and force_value > self.force_limits[force_type]:\n                safety_violations.append(f"Force limit exceeded for {force_type}: {force_value} > {self.force_limits[force_type]}")\n        \n        return len(safety_violations) == 0, safety_violations\n    \n    def monitor_execution(self, robot_state):\n        """Monitor robot execution for safety violations"""\n        if not self.safety_monitoring_active:\n            return True, []\n        \n        # Check for various safety conditions\n        is_safe, violations = self.validate_command(\n            robot_state.get(\'joint_angles\', {}),\n            robot_state.get(\'cartesian_position\', [0,0,0]),\n            robot_state.get(\'applied_forces\', {})\n        )\n        \n        if not is_safe:\n            self.trigger_safety_protocol()\n            return False, violations\n        \n        # Check for fall detection\n        imu_data = robot_state.get(\'imu_data\', {})\n        if self.detect_fall(imu_data):\n            self.fall_detected = True\n            self.trigger_safety_protocol()\n            return False, ["Fall detected"]\n        \n        return True, []\n    \n    def detect_fall(self, imu_data):\n        """Detect if robot is falling based on IMU data"""\n        # Simplified fall detection\n        # Check for excessive angular velocity or acceleration\n        angular_vel = imu_data.get(\'angular_velocity\', [0,0,0])\n        linear_acc = imu_data.get(\'linear_acceleration\', [0,0,0])\n        \n        # Fall threshold (these values would be tuned based on specific robot)\n        ang_vel_threshold = 2.0  # rad/s\n        acc_threshold = 15.0  # m/s^2\n        \n        if np.linalg.norm(angular_vel) > ang_vel_threshold:\n            return True\n        if np.linalg.norm(linear_acc) > acc_threshold:\n            return True\n        \n        return False\n    \n    def trigger_safety_protocol(self):\n        """Trigger safety protocol"""\n        self.emergency_stop = True\n        \n        # Stop all joint movements\n        # Activate joint brakes if available\n        # Go to safe position\n        # Log safety event\n        \n        print("SAFETY PROTOCOL TRIGGERED")\n    \n    def reset_safety(self):\n        """Reset safety state after emergency stop"""\n        self.emergency_stop = False\n        self.fall_detected = False\n        self.over_force_detected = False\n        \n        # Reset other safety flags\n        print("Safety system reset")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"66-practical-example-complete-humanoid-system",children:"6.6 Practical Example: Complete Humanoid System"}),"\n",(0,o.jsx)(n.p,{children:"Let's integrate the concepts to create a complete humanoid robot system:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState, Imu\nfrom geometry_msgs.msg import Pose, Twist\nfrom std_msgs.msg import Float64MultiArray\nfrom builtin_interfaces.msg import Duration\n\nclass HumanoidRobotSystem(Node):\n    def __init__(self):\n        super().__init__('humanoid_robot_system')\n        \n        # Initialize control components\n        self.safety_manager = HumanoidSafetyManager()\n        self.walking_controller = WalkingController()\n        self.cpg_locomotion = LocomotionCPG()\n        self.grasp_planner = GraspPlanner()\n        self.motion_controller = HumanoidMotionController()\n        \n        # ROS 2 interfaces\n        self.joint_state_publisher = self.create_publisher(JointState, '/joint_states', 10)\n        self.imu_subscriber = self.create_subscription(Imu, '/imu', self.imu_callback, 10)\n        self.command_subscriber = self.create_subscription(Float64MultiArray, '/commands', self.command_callback, 10)\n        self.pose_publisher = self.create_publisher(Pose, '/robot_pose', 10)\n        \n        # Robot state\n        self.current_joint_angles = np.zeros(28)  # Example: 28 DOF humanoid\n        self.imu_data = {'angular_velocity': [0,0,0], 'linear_acceleration': [0,0,0]}\n        self.safety_violations = []\n        \n        # Control timer\n        self.control_timer = self.create_timer(0.01, self.control_loop)  # 100 Hz\n        \n        self.get_logger().info('Humanoid Robot System initialized')\n    \n    def imu_callback(self, msg):\n        \"\"\"Handle IMU data\"\"\"\n        self.imu_data = {\n            'angular_velocity': [msg.angular_velocity.x, msg.angular_velocity.y, msg.angular_velocity.z],\n            'linear_acceleration': [msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z]\n        }\n    \n    def command_callback(self, msg):\n        \"\"\"Handle incoming commands\"\"\"\n        # Process and validate commands\n        command_data = np.array(msg.data)\n        \n        # Validate command with safety manager\n        robot_state = {\n            'joint_angles': dict(enumerate(self.current_joint_angles)),\n            'cartesian_position': [0, 0, 0.85],  # Example position\n            'applied_forces': {'gripper_force': 0.0},\n            'imu_data': self.imu_data\n        }\n        \n        is_safe, violations = self.safety_manager.validate_command(\n            robot_state['joint_angles'],\n            robot_state['cartesian_position'],\n            robot_state['applied_forces']\n        )\n        \n        if is_safe:\n            # Execute command\n            self.execute_command(command_data)\n        else:\n            self.safety_violations.extend(violations)\n            self.get_logger().warn(f'Safety violations: {violations}')\n    \n    def execute_command(self, command_data):\n        \"\"\"Execute validated command\"\"\"\n        # Map command data to joint positions\n        if len(command_data) == len(self.current_joint_angles):\n            self.current_joint_angles = command_data\n        else:\n            # Handle command mapping for different formats\n            pass\n    \n    def control_loop(self):\n        \"\"\"Main control loop\"\"\"\n        # Monitor robot safety\n        robot_state = {\n            'joint_angles': dict(enumerate(self.current_joint_angles)),\n            'cartesian_position': [0, 0, 0.85],\n            'applied_forces': {'gripper_force': 0.0},\n            'imu_data': self.imu_data\n        }\n        \n        is_safe, violations = self.safety_manager.monitor_execution(robot_state)\n        \n        if not is_safe:\n            self.safety_violations.extend(violations)\n            # Emergency stop logic\n            self.emergency_stop_sequence()\n            return\n        \n        # Generate joint commands using controllers\n        joint_commands = self.generate_joint_commands()\n        \n        # Publish joint states\n        self.publish_joint_states(joint_commands)\n        \n        # Update CPG for locomotion\n        leg_commands = self.cpg_locomotion.get_leg_commands()\n        \n        # Publish pose estimate\n        self.publish_pose_estimate()\n    \n    def generate_joint_commands(self):\n        \"\"\"Generate joint commands based on current tasks\"\"\"\n        # This would integrate all control systems\n        # For now, return current joint angles\n        return self.current_joint_angles\n    \n    def publish_joint_states(self, joint_positions):\n        \"\"\"Publish joint state information\"\"\"\n        msg = JointState()\n        msg.name = [f'joint_{i}' for i in range(len(joint_positions))]\n        msg.position = joint_positions.tolist()\n        msg.header.stamp = self.get_clock().now().to_msg()\n        \n        self.joint_state_publisher.publish(msg)\n    \n    def publish_pose_estimate(self):\n        \"\"\"Publish robot pose estimate\"\"\"\n        msg = Pose()\n        # Set position based on forward kinematics or estimation\n        msg.position.x = 0.0  # Update with actual position\n        msg.position.y = 0.0\n        msg.position.z = 0.85  # Approximate height\n        \n        # Set orientation (simplified)\n        msg.orientation.w = 1.0  # No rotation initially\n        \n        self.pose_publisher.publish(msg)\n    \n    def emergency_stop_sequence(self):\n        \"\"\"Execute emergency stop sequence\"\"\"\n        self.get_logger().error('EMERGENCY STOP TRIGGERED')\n        \n        # Stop all motion\n        zero_commands = np.zeros_like(self.current_joint_angles)\n        self.current_joint_angles = zero_commands\n        \n        # Go to safe position if possible\n        self.go_to_safe_position()\n        \n        # Log the event\n        self.get_logger().info(f'Safety violations logged: {self.safety_violations}')\n    \n    def go_to_safe_position(self):\n        \"\"\"Move robot to predefined safe position\"\"\"\n        # Define safe joint configurations\n        safe_config = np.zeros_like(self.current_joint_angles)\n        # Set safe positions (standing posture)\n        safe_config[0::2] = 0.0  # Hip joints to neutral\n        safe_config[1::2] = 0.0  # Knee joints to neutral\n        # Other joints as appropriate\n        \n        self.current_joint_angles = safe_config\n\ndef main(args=None):\n    rclpy.init(args=args)\n    \n    # Create and run the humanoid robot system\n    humanoid_system = HumanoidRobotSystem()\n    \n    try:\n        rclpy.spin(humanoid_system)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        humanoid_system.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,o.jsx)(n.h2,{id:"67-summary",children:"6.7 Summary"}),"\n",(0,o.jsx)(n.p,{children:"This chapter has explored the complex field of humanoid robot development, covering:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"The design principles and anthropomorphic considerations in humanoid robotics"}),"\n",(0,o.jsx)(n.li,{children:"The challenges of bipedal locomotion and balance control using ZMP and CPG approaches"}),"\n",(0,o.jsx)(n.li,{children:"The development of dexterous manipulation systems and grasp planning"}),"\n",(0,o.jsx)(n.li,{children:"Multi-limb coordination strategies for complex tasks"}),"\n",(0,o.jsx)(n.li,{children:"Safety systems and emergency protocols for humanoid robots"}),"\n",(0,o.jsx)(n.li,{children:"Integration of all components into a complete humanoid robot system"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Humanoid robots represent one of the most challenging domains in robotics due to their complexity, but they also offer unique advantages for human interaction and environment compatibility."}),"\n",(0,o.jsx)(n.h2,{id:"68-exercises",children:"6.8 Exercises"}),"\n",(0,o.jsx)(n.h3,{id:"exercise-61-bipedal-walking-simulation",children:"Exercise 6.1: Bipedal Walking Simulation"}),"\n",(0,o.jsx)(n.p,{children:"Create a simulation of bipedal walking using ZMP control. Implement a stable walking pattern for a simplified humanoid model."}),"\n",(0,o.jsx)(n.h3,{id:"exercise-62-grasp-planning-algorithm",children:"Exercise 6.2: Grasp Planning Algorithm"}),"\n",(0,o.jsx)(n.p,{children:"Develop a grasp planning algorithm that identifies optimal grasp points on 3D objects and generates appropriate hand configurations."}),"\n",(0,o.jsx)(n.h3,{id:"exercise-63-multi-limb-coordination",children:"Exercise 6.3: Multi-limb Coordination"}),"\n",(0,o.jsx)(n.p,{children:"Implement a system that coordinates movements between multiple limbs while avoiding conflicts and maintaining balance."}),"\n",(0,o.jsx)(n.h3,{id:"exercise-64-safety-system-integration",children:"Exercise 6.4: Safety System Integration"}),"\n",(0,o.jsx)(n.p,{children:"Design and implement a comprehensive safety system for a humanoid robot, including joint limits, fall detection, and emergency protocols."}),"\n",(0,o.jsx)(n.h3,{id:"exercise-65-complete-humanoid-controller",children:"Exercise 6.5: Complete Humanoid Controller"}),"\n",(0,o.jsx)(n.p,{children:"Build a complete control system that integrates walking, manipulation, and safety functions for a humanoid robot."})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>r});var o=t(6540);const i={},s=o.createContext(i);function a(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);