"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[8276],{8038:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var t=r(4848),o=r(8453);const i={sidebar_position:1,title:"Chapter 6: Frontend - Humanoid Robot Development"},s="Chapter 6: Frontend - Humanoid Robot Development",a={id:"chapter-06/intro-frontend",title:"Chapter 6: Frontend - Humanoid Robot Development",description:"Learning Objectives",source:"@site/docs/chapter-06/01-intro-frontend.md",sourceDirName:"chapter-06",slug:"/chapter-06/intro-frontend",permalink:"/docs/chapter-06/intro-frontend",draft:!1,unlisted:!1,editUrl:"https://github.com/tabindaseher/Physical-AI-Humanoid-Robotics/edit/main/docs/chapter-06/01-intro-frontend.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"Chapter 6: Frontend - Humanoid Robot Development"},sidebar:"tutorialSidebar",previous:{title:"Chapter 5 Exercises",permalink:"/docs/chapter-05/exercises"},next:{title:"Chapter 6 Learning Outcomes",permalink:"/docs/chapter-06/learning-outcomes"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"6.1 Humanoid Robot Design Principles",id:"61-humanoid-robot-design-principles",level:2},{value:"Anthropomorphic Design Considerations",id:"anthropomorphic-design-considerations",level:3},{value:"Degrees of Freedom and Mobility",id:"degrees-of-freedom-and-mobility",level:3},{value:"Actuator Selection and Placement",id:"actuator-selection-and-placement",level:3},{value:"Structural Materials and Fabrication",id:"structural-materials-and-fabrication",level:3},{value:"6.2 Locomotion and Gait Control",id:"62-locomotion-and-gait-control",level:2},{value:"Bipedal Walking Mechanics",id:"bipedal-walking-mechanics",level:3},{value:"Zero Moment Point (ZMP) Control",id:"zero-moment-point-zmp-control",level:3},{value:"Gait Pattern Generation",id:"gait-pattern-generation",level:3},{value:"6.3 Manipulation and Dexterity",id:"63-manipulation-and-dexterity",level:2},{value:"Anthropomorphic Hands and Fingers",id:"anthropomorphic-hands-and-fingers",level:3},{value:"Grasp Planning and Execution",id:"grasp-planning-and-execution",level:3},{value:"Multi-limb Coordination",id:"multi-limb-coordination",level:3},{value:"6.4 Humanoid Control Architectures",id:"64-humanoid-control-architectures",level:2},{value:"Hierarchical Control Systems",id:"hierarchical-control-systems",level:3},{value:"Central Pattern Generators (CPGs)",id:"central-pattern-generators-cpgs",level:3},{value:"6.5 Safety and Emergency Systems",id:"65-safety-and-emergency-systems",level:2},{value:"Humanoid Safety Manager",id:"humanoid-safety-manager",level:3},{value:"6.6 Practical Example: Complete Humanoid System",id:"66-practical-example-complete-humanoid-system",level:2},{value:"6.7 Summary",id:"67-summary",level:2},{value:"6.8 Exercises",id:"68-exercises",level:2},{value:"Exercise 6.1: Bipedal Walking Simulation",id:"exercise-61-bipedal-walking-simulation",level:3},{value:"Exercise 6.2: Grasp Planning Algorithm",id:"exercise-62-grasp-planning-algorithm",level:3},{value:"Exercise 6.3: Multi-limb Coordination",id:"exercise-63-multi-limb-coordination",level:3},{value:"Exercise 6.4: Safety System Integration",id:"exercise-64-safety-system-integration",level:3},{value:"Exercise 6.5: Complete Humanoid Controller",id:"exercise-65-complete-humanoid-controller",level:3}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"chapter-6-frontend---humanoid-robot-development",children:"Chapter 6: Frontend - Humanoid Robot Development"}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this chapter, you should be able to:"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Remember"}),": List the key components and design principles of humanoid robot development"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Understand"}),": Explain the biomechanics, dynamics, and control challenges of humanoid robots"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Apply"}),": Design and implement control systems for humanoid robot locomotion and manipulation"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Analyze"}),": Evaluate the gait stability and balance systems in humanoid robots"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Evaluate"}),": Compare different humanoid robot platforms and their capabilities"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Create"}),": Develop a complete humanoid robot subsystem with perception, control, and safety"]}),"\n",(0,t.jsx)(n.h2,{id:"61-humanoid-robot-design-principles",children:"6.1 Humanoid Robot Design Principles"}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots are designed to mimic human form and function, which provides unique advantages and challenges in robotics. The human-like form factor enables interaction with human environments and tools, but also requires sophisticated control systems to replicate human capabilities."}),"\n",(0,t.jsx)(n.h3,{id:"anthropomorphic-design-considerations",children:"Anthropomorphic Design Considerations"}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots incorporate human-like features that serve both functional and social purposes:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Bipedal Locomotion"}),": Two-legged walking capability similar to humans"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Upper Limb Manipulation"}),": Arms and hands designed for dexterous manipulation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensory Systems"}),": Vision, hearing, and tactile systems positioned similarly to humans"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Communication Interface"}),": Face and body language for human-robot interaction"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"degrees-of-freedom-and-mobility",children:"Degrees of Freedom and Mobility"}),"\n",(0,t.jsx)(n.p,{children:"The number and arrangement of joints significantly impact a humanoid robot's capabilities:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class HumanoidRobotConfig:\r\n    def __init__(self):\r\n        # Define joint configuration similar to human body\r\n        self.left_leg = {\r\n            'hip_yaw_pitch': {'range': (-45, 45), 'type': 'revolute'},\r\n            'hip_roll': {'range': (-20, 45), 'type': 'revolute'},\r\n            'hip_pitch': {'range': (-120, 30), 'type': 'revolute'},\r\n            'knee': {'range': (0, 135), 'type': 'revolute'},\r\n            'ankle_pitch': {'range': (-45, 45), 'type': 'revolute'},\r\n            'ankle_roll': {'range': (-20, 20), 'type': 'revolute'}\r\n        }\r\n        \r\n        self.right_leg = self._mirror_joints(self.left_leg)\r\n        \r\n        self.left_arm = {\r\n            'shoulder_pitch': {'range': (-120, 120), 'type': 'revolute'},\r\n            'shoulder_roll': {'range': (-90, 30), 'type': 'revolute'},\r\n            'shoulder_yaw': {'range': (-120, 120), 'type': 'revolute'},\r\n            'elbow': {'range': (0, 160), 'type': 'revolute'},\r\n            'wrist_yaw': {'range': (-120, 120), 'type': 'revolute'},\r\n            'wrist_pitch': {'range': (-90, 90), 'type': 'revolute'},\r\n            'wrist_roll': {'range': (-120, 120), 'type': 'revolute'}\r\n        }\r\n        \r\n        self.right_arm = self._mirror_joints(self.left_arm)\r\n        \r\n        self.torso = {\r\n            'waist_yaw': {'range': (-60, 60), 'type': 'revolute'},\r\n            'waist_pitch': {'range': (-30, 30), 'type': 'revolute'},\r\n            'waist_roll': {'range': (-30, 30), 'type': 'revolute'}\r\n        }\r\n        \r\n        self.head = {\r\n            'neck_yaw': {'range': (-120, 120), 'type': 'revolute'},\r\n            'neck_pitch': {'range': (-30, 60), 'type': 'revolute'},\r\n            'neck_roll': {'range': (-30, 30), 'type': 'revolute'}\r\n        }\r\n    \r\n    def _mirror_joints(self, joints):\r\n        \"\"\"Create mirror configuration for opposite side\"\"\"\r\n        mirrored = {}\r\n        for name, props in joints.items():\r\n            mirrored[name] = props.copy()\r\n        return mirrored\r\n    \r\n    def get_total_dof(self):\r\n        \"\"\"Calculate total degrees of freedom\"\"\"\r\n        total = 0\r\n        for limb in [self.left_leg, self.right_leg, self.left_arm, self.right_arm, \r\n                     self.torso, self.head]:\r\n            total += len(limb)\r\n        return total\r\n\r\n# Example usage\r\nrobot_config = HumanoidRobotConfig()\r\nprint(f\"Total DOF: {robot_config.get_total_dof()}\")\n"})}),"\n",(0,t.jsx)(n.h3,{id:"actuator-selection-and-placement",children:"Actuator Selection and Placement"}),"\n",(0,t.jsx)(n.p,{children:"Selecting appropriate actuators for humanoid robots requires balancing power, precision, and safety:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Servo Motors"}),": High precision, good for manipulation tasks"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Series Elastic Actuators (SEA)"}),": Compliant actuation for safe interaction"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Pneumatic Muscles"}),": Human-like compliance and lightweight design"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hydraulic Actuators"}),": High power-to-weight ratio for heavy lifting"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"structural-materials-and-fabrication",children:"Structural Materials and Fabrication"}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots require materials that balance strength, weight, and safety:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Aluminum Alloys"}),": Lightweight with good strength-to-weight ratio"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Carbon Fiber"}),": Extremely lightweight with high strength"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Engineering Plastics"}),": Cost-effective for non-critical components"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Titanium"}),": High strength applications requiring corrosion resistance"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"62-locomotion-and-gait-control",children:"6.2 Locomotion and Gait Control"}),"\n",(0,t.jsx)(n.h3,{id:"bipedal-walking-mechanics",children:"Bipedal Walking Mechanics"}),"\n",(0,t.jsx)(n.p,{children:"Bipedal walking presents unique challenges due to the need for dynamic balance:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Single Support Phase"}),": One foot in contact with ground"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Double Support Phase"}),": Both feet in contact with ground"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Swing Phase"}),": Leg moves forward without ground contact"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Balance Control"}),": Maintaining center of mass within support polygon"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\r\nfrom scipy import integrate\r\nimport matplotlib.pyplot as plt\r\n\r\nclass BipedalWalker:\r\n    def __init__(self, mass=70, leg_length=0.9, gravity=9.81):\r\n        self.mass = mass  # kg\r\n        self.leg_length = leg_length  # m\r\n        self.gravity = gravity  # m/s^2\r\n        \r\n        # Walking parameters\r\n        self.step_length = 0.3  # m\r\n        self.step_height = 0.1  # m\r\n        self.gait_cycle_time = 1.0  # s\r\n        \r\n        # State variables\r\n        self.x = 0.0  # x position\r\n        self.y = 0.0  # y position (lateral movement)\r\n        self.z = leg_length  # z position (height)\r\n        self.omega = 0.0  # angular velocity\r\n        \r\n        # Control parameters\r\n        self.com_height = 0.85  # Center of mass height\r\n        self.zmp_x = 0.0  # Zero Moment Point x-coordinate\r\n        self.zmp_y = 0.0  # Zero Moment Point y-coordinate\r\n        \r\n    def inverted_pendulum_model(self, state, t):\r\n        """\r\n        Inverted pendulum model for bipedal walking\r\n        state = [x, y, z, dx, dy, dz, theta_x, theta_y, omega_x, omega_y]\r\n        """\r\n        x, y, z, dx, dy, dz, theta_x, theta_y, omega_x, omega_y = state\r\n        \r\n        # Simplified inverted pendulum dynamics\r\n        x_dd = self.gravity / (z - self.com_height) * theta_x\r\n        y_dd = self.gravity / (z - self.com_height) * theta_y\r\n        \r\n        # Angular velocity derivatives\r\n        theta_x_d = omega_x\r\n        theta_y_d = omega_y\r\n        \r\n        return [dx, dy, dz, x_dd, y_dd, 0, theta_x_d, theta_y_d, 0, 0]\r\n    \r\n    def compute_zmp(self, x, y, z, dx, dy, dz):\r\n        """\r\n        Compute Zero Moment Point (ZMP) for balance control\r\n        """\r\n        # ZMP calculation based on center of mass and ground reaction forces\r\n        zmp_x = x - (z - self.com_height) / self.gravity * dx\r\n        zmp_y = y - (z - self.com_height) / self.gravity * dy\r\n        \r\n        return zmp_x, zmp_y\r\n    \r\n    def generate_com_trajectory(self, start_pos, goal_pos, duration):\r\n        """\r\n        Generate Center of Mass trajectory for walking\r\n        """\r\n        # Simple 5th order polynomial trajectory\r\n        t = np.linspace(0, duration, int(duration * 100))  # 100 Hz sampling\r\n        \r\n        # Generate trajectory for each axis\r\n        x_traj = np.linspace(start_pos[0], goal_pos[0], len(t))\r\n        y_traj = np.full_like(t, self.com_height)  # Keep CoM at constant height\r\n        z_traj = np.full_like(t, self.com_height)  # Constant height\r\n        \r\n        # Add small lateral movement for balance\r\n        y_traj += 0.05 * np.sin(2 * np.pi * t / duration)\r\n        \r\n        return t, np.column_stack([x_traj, y_traj, z_traj])\r\n    \r\n    def step_pattern_generator(self, step_length, step_height, step_time):\r\n        """\r\n        Generate step pattern for walking gait\r\n        """\r\n        t = np.linspace(0, step_time, int(step_time * 100))\r\n        \r\n        # Swing leg trajectory\r\n        x_swing = step_length * (1 - np.cos(np.pi * t / step_time)) / 2\r\n        z_swing = step_height * np.sin(np.pi * t / step_time)\r\n        \r\n        # Support leg stays relatively constant but with small adjustments\r\n        x_support = np.full_like(t, step_length / 2)  # Average position\r\n        z_support = np.full_like(t, 0)  # Ground level\r\n        \r\n        return {\r\n            \'swing_leg\': np.column_stack([x_swing, np.zeros_like(x_swing), z_swing]),\r\n            \'support_leg\': np.column_stack([x_support, np.zeros_like(x_support), z_support])\r\n        }\r\n\r\nclass WalkingController:\r\n    def __init__(self):\r\n        self.biped_model = BipedalWalker()\r\n        self.zmp_reference = np.array([0.0, 0.0])\r\n        self.com_reference = np.array([0.0, 0.0, 0.85])\r\n        \r\n        # Controller gains\r\n        self.k_p = 10.0  # Proportional gain\r\n        self.k_d = 2.0   # Derivative gain\r\n        self.k_i = 1.0   # Integral gain\r\n        \r\n    def zmp_controller(self, current_zmp, dt):\r\n        """ZMP-based balance controller"""\r\n        error = self.zmp_reference - current_zmp\r\n        self.integral_error += error * dt\r\n        \r\n        # PID control for balance\r\n        control_output = self.k_p * error + self.k_i * self.integral_error\r\n        return control_output\r\n    \r\n    def compute_foot_placement(self, com_state, target_velocity):\r\n        """Compute optimal foot placement for balance"""\r\n        # Simple model for foot placement based on inverted pendulum\r\n        # Calculate where to place foot to maintain balance\r\n        com_x, com_y, com_z = com_state\r\n        com_x_dot, com_y_dot = target_velocity[:2]\r\n        \r\n        # Time to foot placement\r\n        support_time = 0.8  # seconds\r\n        \r\n        # Predict where CoM will be\r\n        predicted_x = com_x + com_x_dot * support_time\r\n        predicted_y = com_y + com_y_dot * support_time\r\n        \r\n        # Add safety margin\r\n        foot_x = predicted_x + 0.1  # Small forward margin\r\n        foot_y = com_y + 0.0  # Stay in line with CoM y\r\n        \r\n        return np.array([foot_x, foot_y, 0.0])\n'})}),"\n",(0,t.jsx)(n.h3,{id:"zero-moment-point-zmp-control",children:"Zero Moment Point (ZMP) Control"}),"\n",(0,t.jsx)(n.p,{children:"ZMP control is fundamental to humanoid balance during walking:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class ZMPController:\r\n    def __init__(self, robot_mass, com_height, gravity=9.81):\r\n        self.mass = robot_mass\r\n        self.com_height = com_height\r\n        self.gravity = gravity\r\n        self.integral_error = np.zeros(2)\r\n        \r\n        # Controller parameters\r\n        self.kp = 100.0  # Proportional gain\r\n        self.kd = 10.0   # Derivative gain \r\n        self.ki = 1.0    # Integral gain\r\n        \r\n    def compute_zmp(self, com_pos, com_vel, com_acc, cop_pos):\r\n        """\r\n        Compute Zero Moment Point based on CoM and CoP information\r\n        """\r\n        # ZMP_x = CoM_x - (CoM_z - h) / g * CoM_acc_x\r\n        # ZMP_y = CoM_y - (CoM_z - h) / g * CoM_acc_y\r\n        \r\n        zmp = np.array([\r\n            com_pos[0] - (com_pos[2] - self.com_height) / self.gravity * com_acc[0],\r\n            com_pos[1] - (com_pos[2] - self.com_height) / self.gravity * com_acc[1]\r\n        ])\r\n        \r\n        return zmp\r\n    \r\n    def balance_control(self, current_zmp, reference_zmp, dt):\r\n        """\r\n        Compute control forces to maintain balance\r\n        """\r\n        # Calculate error\r\n        error = reference_zmp - current_zmp\r\n        \r\n        # Update integral term\r\n        self.integral_error += error * dt\r\n        \r\n        # Compute control output (PID)\r\n        control_output = (\r\n            self.kp * error + \r\n            self.kd * (error - self.previous_error) / dt + \r\n            self.ki * self.integral_error\r\n        )\r\n        \r\n        self.previous_error = error.copy()\r\n        \r\n        return control_output\r\n    \r\n    def update_reference_zmp(self, com_pos, target_pos, stiffness=1.0):\r\n        """\r\n        Update reference ZMP based on desired center of mass position\r\n        """\r\n        # Simple spring-mass tracking of desired position\r\n        pos_error = target_pos - com_pos[:2]\r\n        reference_zmp = target_pos - stiffness * pos_error\r\n        \r\n        # Keep reference within support polygon\r\n        reference_zmp = self.constrain_to_support_polygon(reference_zmp)\r\n        \r\n        return reference_zmp\r\n    \r\n    def constrain_to_support_polygon(self, zmp):\r\n        """\r\n        Constrain ZMP to be within the convex hull of foot support points\r\n        """\r\n        # For a simple case with rectangular feet\r\n        foot_width = 0.1  # meters\r\n        foot_length = 0.15  # meters\r\n        \r\n        # This would be more complex in a real implementation\r\n        constrained_zmp = np.clip(zmp, [-foot_width/2, -foot_length/2], \r\n                                [foot_width/2, foot_length/2])\r\n        \r\n        return constrained_zmp\n'})}),"\n",(0,t.jsx)(n.h3,{id:"gait-pattern-generation",children:"Gait Pattern Generation"}),"\n",(0,t.jsx)(n.p,{children:"Creating stable walking patterns requires sophisticated trajectory planning:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class GaitPatternGenerator:\r\n    def __init__(self, step_length=0.3, step_height=0.1, step_time=0.8):\r\n        self.step_length = step_length\r\n        self.step_height = step_height\r\n        self.step_time = step_time\r\n        \r\n        # Walking parameters\r\n        self.stride_length = 2 * step_length  # Distance between foot placements\r\n        self.walking_speed = self.stride_length / step_time  # m/s\r\n        \r\n    def generate_walk_trajectory(self, num_steps, start_pos=np.array([0, 0, 0])):\r\n        """\r\n        Generate complete walking trajectory for specified number of steps\r\n        """\r\n        trajectory = []\r\n        time_points = []\r\n        \r\n        current_pos = start_pos.copy()\r\n        \r\n        for step in range(num_steps):\r\n            # Generate single step trajectory\r\n            step_trajectory, step_times = self.generate_single_step(\r\n                current_pos, step % 2  # Alternate between left/right foot\r\n            )\r\n            \r\n            # Update current position for next step\r\n            current_pos[0] += self.stride_length / 2  # Move forward by half a stride\r\n            \r\n            trajectory.extend(step_trajectory)\r\n            time_points.extend(step_times)\r\n        \r\n        return np.array(trajectory), np.array(time_points)\r\n    \r\n    def generate_single_step(self, start_pos, foot_index):\r\n        """\r\n        Generate trajectory for a single step (either left or right foot)\r\n        foot_index: 0 for left foot, 1 for right foot\r\n        """\r\n        t = np.linspace(0, self.step_time, int(self.step_time * 100))  # 100 Hz\r\n        \r\n        # Swing foot trajectory (parabolic for smooth movement)\r\n        x_swing = start_pos[0] + self.step_length * (1 - np.cos(np.pi * t / self.step_time)) / 2\r\n        y_swing = start_pos[1] + (-1)**foot_index * 0.15  # Offset for left/right foot\r\n        z_swing = start_pos[2] + self.step_height * np.sin(np.pi * t / self.step_time)\r\n        \r\n        # Support foot trajectory (minimal movement)\r\n        x_support = start_pos[0] * np.ones_like(t)\r\n        y_support = start_pos[1] + (-1)**(1-foot_index) * 0.15  # Opposite foot position\r\n        z_support = start_pos[2] * np.ones_like(t)  # Ground level\r\n        \r\n        step_trajectory = []\r\n        for i in range(len(t)):\r\n            if foot_index == 0:  # Left foot is swing foot\r\n                step_trajectory.append([\r\n                    x_swing[i], y_swing[i], z_swing[i],  # Left foot\r\n                    x_support[i], y_support[i], z_support[i]  # Right foot\r\n                ])\r\n            else:  # Right foot is swing foot\r\n                step_trajectory.append([\r\n                    x_support[i], y_support[i], z_support[i],  # Left foot\r\n                    x_swing[i], y_swing[i], z_swing[i]  # Right foot\r\n                ])\r\n        \r\n        return step_trajectory, t.tolist()\r\n    \r\n    def adjust_for_obstacles(self, trajectory, obstacle_positions):\r\n        """\r\n        Adjust gait pattern to avoid obstacles\r\n        """\r\n        # This would implement obstacle avoidance during walking\r\n        # For now, a simplified version\r\n        adjusted_trajectory = trajectory.copy()\r\n        \r\n        for i, pos in enumerate(adjusted_trajectory):\r\n            for obs_pos in obstacle_positions:\r\n                if self.distance_to_obstacle(pos[:2], obs_pos[:2]) < 0.3:  # 30cm clearance\r\n                    # Adjust step to go around obstacle\r\n                    adjusted_trajectory[i][0] += 0.1  # Move slightly to the side\r\n                    adjusted_trajectory[i][3] += 0.1  # Move support foot too\r\n        \r\n        return adjusted_trajectory\r\n    \r\n    def distance_to_obstacle(self, point1, point2):\r\n        """Calculate distance between two 2D points"""\r\n        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"63-manipulation-and-dexterity",children:"6.3 Manipulation and Dexterity"}),"\n",(0,t.jsx)(n.h3,{id:"anthropomorphic-hands-and-fingers",children:"Anthropomorphic Hands and Fingers"}),"\n",(0,t.jsx)(n.p,{children:"Creating dexterous hands remains one of the greatest challenges in humanoid robotics:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Underactuation"}),": Using fewer actuators than degrees of freedom"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tendon-driven systems"}),": Mimicking human muscle-tendon systems"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Compliant mechanisms"}),": Built-in compliance for safe interaction"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tactile sensing"}),": Feedback for grasp stability and object properties"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"grasp-planning-and-execution",children:"Grasp Planning and Execution"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import open3d as o3d\r\nfrom scipy.spatial.distance import cdist\r\nimport numpy as np\r\n\r\nclass GraspPlanner:\r\n    def __init__(self):\r\n        # Grasp primitive types\r\n        self.grasp_types = [\r\n            \'precision_pinch\', \r\n            \'power_grasp\', \r\n            \'spherical_grasp\',\r\n            \'circular_grasp\',\r\n            \'lateral_grasp\'\r\n        ]\r\n        \r\n        # Hand kinematics (simplified)\r\n        self.finger_lengths = [0.04, 0.035, 0.03]  # Three segments per finger\r\n        self.hand_width = 0.08  # Maximum hand opening\r\n        self.finger_count = 5\r\n        \r\n    def find_grasp_points(self, object_mesh):\r\n        """\r\n        Find potential grasp points on object surface\r\n        """\r\n        # Sample points on object surface\r\n        surface_points = self.sample_surface_points(object_mesh)\r\n        \r\n        # Analyze object geometry to find suitable grasp locations\r\n        grasp_candidates = []\r\n        \r\n        for point in surface_points:\r\n            # Check for suitable grasp direction at this point\r\n            normal = self.estimate_surface_normal(object_mesh, point)\r\n            \r\n            # Calculate approach direction (orthogonal to normal)\r\n            approach_dirs = self.generate_approach_directions(normal)\r\n            \r\n            for approach_dir in approach_dirs:\r\n                if self.is_stable_grasp(object_mesh, point, approach_dir):\r\n                    grasp_candidates.append({\r\n                        \'position\': point,\r\n                        \'normal\': normal,\r\n                        \'approach\': approach_dir,\r\n                        \'quality\': self.evaluate_grasp_quality(object_mesh, point, approach_dir)\r\n                    })\r\n        \r\n        # Sort candidates by quality score\r\n        grasp_candidates.sort(key=lambda x: x[\'quality\'], reverse=True)\r\n        \r\n        return grasp_candidates\r\n    \r\n    def sample_surface_points(self, mesh, num_points=100):\r\n        """Sample points on mesh surface"""\r\n        pcd = mesh.sample_points_uniformly(number_of_points=num_points)\r\n        return np.asarray(pcd.points)\r\n    \r\n    def estimate_surface_normal(self, mesh, point):\r\n        """Estimate surface normal at a point"""\r\n        # In practice, this would use mesh normals or point cloud analysis\r\n        # For this example, we\'ll return a dummy normal\r\n        return np.array([0, 0, 1])  # Default upward normal\r\n    \r\n    def generate_approach_directions(self, normal):\r\n        """Generate possible approach directions orthogonal to surface normal"""\r\n        # Generate directions perpendicular to surface normal\r\n        # This is a simplified implementation\r\n        directions = []\r\n        \r\n        # Create rotation matrix to get orthogonal directions\r\n        z_axis = normal / np.linalg.norm(normal)\r\n        \r\n        # Find one orthogonal vector\r\n        if abs(z_axis[2]) < 0.9:\r\n            x_axis = np.cross(z_axis, [0, 0, 1])\r\n        else:\r\n            x_axis = np.cross(z_axis, [1, 0, 0])\r\n        \r\n        x_axis = x_axis / np.linalg.norm(x_axis)\r\n        y_axis = np.cross(z_axis, x_axis)\r\n        \r\n        # Generate multiple approach directions\r\n        for angle in np.linspace(0, 2*np.pi, 8):\r\n            direction = np.cos(angle) * x_axis + np.sin(angle) * y_axis\r\n            directions.append(direction)\r\n        \r\n        return directions\r\n    \r\n    def is_stable_grasp(self, object_mesh, point, approach_dir):\r\n        """Check if a grasp is geometrically stable"""\r\n        # Check if approach direction allows for a stable grip\r\n        # This would involve checking for adequate contact areas\r\n        # and force closure properties\r\n        \r\n        # Simplified check: ensure approach direction doesn\'t intersect\r\n        # with object in a way that prevents grasping\r\n        grasp_length = 0.03  # Typical grasp depth\r\n        grasp_end = point - grasp_length * approach_dir / np.linalg.norm(approach_dir)\r\n        \r\n        # Check if line from point to grasp_end intersects object\r\n        # (indicating grasp would be blocked)\r\n        intersection = self.check_line_mesh_intersection(\r\n            point, grasp_end, object_mesh\r\n        )\r\n        \r\n        return not intersection\r\n    \r\n    def check_line_mesh_intersection(self, start, end, mesh):\r\n        """Check if line intersects with mesh"""\r\n        # Simplified intersection check\r\n        # In practice, this would use ray-casting or geometric algorithms\r\n        return False\r\n    \r\n    def evaluate_grasp_quality(self, object_mesh, point, approach_dir):\r\n        """Evaluate the quality of a potential grasp"""\r\n        # Consider factors like:\r\n        # - Surface curvature at contact point\r\n        # - Object size relative to hand\r\n        # - Approach accessibility\r\n        # - Stability of grasp\r\n        \r\n        quality = 0.0\r\n        \r\n        # Curvature consideration (flatter surfaces are better for grasping)\r\n        curvature = self.estimate_curvature(object_mesh, point)\r\n        quality += max(0, 1.0 - abs(curvature) * 10)  # Lower curvature = better\r\n        \r\n        # Size consideration (object should fit in hand)\r\n        object_size = self.estimate_object_size(object_mesh)\r\n        if object_size < self.hand_width:\r\n            quality += 0.3\r\n        else:\r\n            quality += max(0, 0.3 * (self.hand_width / object_size))\r\n        \r\n        # Approach accessibility\r\n        accessibility = self.evaluate_approach_accessibility(point, approach_dir)\r\n        quality += accessibility * 0.4\r\n        \r\n        return min(quality, 1.0)\r\n    \r\n    def estimate_curvature(self, mesh, point):\r\n        """Estimate surface curvature at a point"""\r\n        # Simplified curvature estimation\r\n        return 0.0  # For now, assume flat surface\r\n    \r\n    def estimate_object_size(self, mesh):\r\n        """Estimate characteristic size of object"""\r\n        bounds = mesh.get_axis_aligned_bounding_box()\r\n        dims = bounds.get_extent()\r\n        return max(dims)\r\n    \r\n    def evaluate_approach_accessibility(self, point, approach_dir):\r\n        """Evaluate how accessible the approach is"""\r\n        # Consider obstacles, robot configuration, etc.\r\n        return 1.0  # Assume fully accessible for this example\r\n    \r\n    def plan_hand_trajectory(self, grasp_pose, pre_grasp_offset=0.05):\r\n        """\r\n        Plan trajectory to move hand to grasp position\r\n        """\r\n        # Calculate pre-grasp pose (approach from safe distance)\r\n        pre_grasp_pose = grasp_pose.copy()\r\n        pre_grasp_pose[:3] += pre_grasp_offset * grasp_pose[3:6]  # Move along approach vector\r\n        \r\n        # Plan trajectory through joint space\r\n        trajectory = self.interpolate_trajectory(pre_grasp_pose, grasp_pose)\r\n        \r\n        return trajectory\r\n    \r\n    def interpolate_trajectory(self, start_pose, end_pose, steps=50):\r\n        """Interpolate between two poses"""\r\n        trajectory = []\r\n        \r\n        for i in range(steps + 1):\r\n            t = i / steps\r\n            pose = (1 - t) * start_pose + t * end_pose\r\n            trajectory.append(pose)\r\n        \r\n        return trajectory\r\n\r\nclass HandController:\r\n    def __init__(self):\r\n        self.finger_positions = np.zeros(5)  # 5 fingers\r\n        self.finger_velocities = np.zeros(5)\r\n        self.finger_forces = np.zeros(5)\r\n        \r\n        # Grasp parameters\r\n        self.grasp_force_limits = [10, 10, 10, 10, 10]  # N\r\n        self.finger_range = [0, 90]  # degrees\r\n        \r\n    def execute_grasp(self, grasp_type, force_multiplier=1.0):\r\n        """Execute a specific type of grasp"""\r\n        if grasp_type == \'precision_pinch\':\r\n            # Move thumb and index finger together\r\n            self.finger_positions[0] = 60  # Thumb\r\n            self.finger_positions[1] = 60  # Index finger\r\n            # Keep other fingers in neutral position\r\n            self.finger_positions[2:] = 10  # Other fingers slightly curled\r\n            \r\n        elif grasp_type == \'power_grasp\':\r\n            # Close all fingers for power grasp\r\n            self.finger_positions = np.full(5, 80)  # Close all fingers\r\n            \r\n        elif grasp_type == \'cylindrical_grasp\':\r\n            # Grasp cylindrical objects\r\n            self.finger_positions[0] = 70  # Thumb wraps around\r\n            self.finger_positions[1:] = 60  # Other fingers close on opposite side\r\n            \r\n        # Apply force proportional to grasp type requirements\r\n        self.finger_forces = self.calculate_grasp_forces(grasp_type, force_multiplier)\r\n        \r\n        return self.finger_positions.copy(), self.finger_forces.copy()\r\n    \r\n    def calculate_grasp_forces(self, grasp_type, force_multiplier):\r\n        """Calculate appropriate grasp forces for different grasp types"""\r\n        base_forces = {\r\n            \'precision_pinch\': [5, 5, 1, 1, 1],\r\n            \'power_grasp\': [8, 8, 8, 8, 8],\r\n            \'cylindrical_grasp\': [6, 8, 8, 8, 8],\r\n            \'spherical_grasp\': [7, 7, 7, 7, 7],\r\n            \'lateral_grasp\': [10, 2, 1, 1, 1]\r\n        }\r\n        \r\n        forces = np.array(base_forces.get(grasp_type, [5, 5, 5, 5, 5]))\r\n        forces *= force_multiplier\r\n        \r\n        # Ensure forces are within limits\r\n        forces = np.clip(forces, 0, self.grasp_force_limits)\r\n        \r\n        return forces\r\n    \r\n    def adjust_grasp(self, tactile_feedback):\r\n        """\r\n        Adjust grasp based on tactile feedback\r\n        tactile_feedback: array with pressure info from tactile sensors\r\n        """\r\n        # Simple adjustment algorithm\r\n        if np.any(tactile_feedback > 0.8 * self.grasp_force_limits):\r\n            # Too much force detected, reduce slightly\r\n            self.finger_forces *= 0.95\r\n        elif np.any(tactile_feedback < 0.2 * self.grasp_force_limits):\r\n            # Not enough force for secure grasp, increase slightly\r\n            self.finger_forces *= 1.02\r\n            # Limit maximum force\r\n            self.finger_forces = np.clip(self.finger_forces, 0, self.grasp_force_limits)\r\n        \r\n        return self.finger_forces.copy()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"multi-limb-coordination",children:"Multi-limb Coordination"}),"\n",(0,t.jsx)(n.p,{children:"Coordinating multiple limbs in humanoid robots requires sophisticated control:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"class MultiLimbCoordinator:\r\n    def __init__(self):\r\n        # Define limb coordination priorities\r\n        self.limb_priorities = {\r\n            'right_arm': 1,\r\n            'left_arm': 2, \r\n            'right_leg': 3,\r\n            'left_leg': 4\r\n        }\r\n        \r\n        # Task coordination system\r\n        self.active_tasks = {}\r\n        self.task_dependencies = {}\r\n        \r\n    def coordinate_task_execution(self, tasks):\r\n        \"\"\"\r\n        Coordinate execution of multiple tasks across different limbs\r\n        \"\"\"\r\n        # Resolve task conflicts and dependencies\r\n        resolved_tasks = self.resolve_conflicts(tasks)\r\n        \r\n        # Schedule task execution\r\n        execution_plan = self.schedule_tasks(resolved_tasks)\r\n        \r\n        return execution_plan\r\n    \r\n    def resolve_conflicts(self, tasks):\r\n        \"\"\"Resolve conflicts between simultaneous tasks\"\"\"\r\n        resolved_tasks = {}\r\n        \r\n        for limb, task in tasks.items():\r\n            conflict = self.check_task_conflict(limb, task)\r\n            if conflict:\r\n                # Resolve conflict based on priority\r\n                if self.limb_priorities[limb] < self.limb_priorities[conflict['conflicting_limb']]:\r\n                    # This limb has higher priority, adjust other task\r\n                    resolved_tasks[conflict['conflicting_limb']] = self.adjust_task(\r\n                        tasks[conflict['conflicting_limb']]\r\n                    )\r\n                else:\r\n                    # Lower priority task needs adjustment\r\n                    resolved_tasks[limb] = self.adjust_task(task)\r\n            else:\r\n                resolved_tasks[limb] = task\r\n        \r\n        return resolved_tasks\r\n    \r\n    def check_task_conflict(self, limb, task):\r\n        \"\"\"Check if a task conflicts with other active tasks\"\"\"\r\n        # For now, a simple check for collision in workspace\r\n        # In practice, this would check for workspace, timing, and priority conflicts\r\n        return None\r\n    \r\n    def adjust_task(self, original_task):\r\n        \"\"\"Adjust task to avoid conflicts\"\"\"\r\n        # Create a modified version of the task that avoids conflicts\r\n        adjusted_task = original_task.copy()\r\n        # Add delays, modify parameters, etc.\r\n        return adjusted_task\r\n    \r\n    def schedule_tasks(self, resolved_tasks):\r\n        \"\"\"Schedule tasks for execution across different limbs\"\"\"\r\n        # Create temporal schedule for task execution\r\n        schedule = {}\r\n        \r\n        for limb, task in resolved_tasks.items():\r\n            # Assign execution time based on task requirements\r\n            schedule[limb] = {\r\n                'task': task,\r\n                'start_time': self.calculate_start_time(task),\r\n                'duration': self.calculate_duration(task),\r\n                'priority': self.limb_priorities[limb]\r\n            }\r\n        \r\n        # Sort by start time and priority\r\n        sorted_schedule = sorted(schedule.items(), \r\n                               key=lambda x: (x[1]['start_time'], x[1]['priority']))\r\n        \r\n        return sorted_schedule\r\n\r\nclass HumanoidMotionController:\r\n    def __init__(self):\r\n        self.walking_controller = WalkingController()\r\n        self.grasp_planner = GraspPlanner()\r\n        self.multi_limb_coordinator = MultiLimbCoordinator()\r\n        self.safety_manager = HumanoidSafetyManager()\r\n        \r\n    def execute_complex_task(self, task_description):\r\n        \"\"\"\r\n        Execute complex tasks that involve multiple limbs and modalities\r\n        \"\"\"\r\n        # Parse high-level task into component actions\r\n        subtasks = self.parse_task(task_description)\r\n        \r\n        # Coordinate execution across different limbs\r\n        execution_plan = self.multi_limb_coordinator.coordinate_task_execution(subtasks)\r\n        \r\n        # Execute each component while maintaining safety\r\n        for limb, task_info in execution_plan:\r\n            if self.safety_manager.is_safe_to_execute(task_info['task']):\r\n                # Execute the task component\r\n                result = self.execute_task_component(limb, task_info['task'])\r\n                \r\n                # Monitor execution for safety\r\n                self.safety_manager.monitor_execution(result)\r\n            else:\r\n                # Safety check failed, handle accordingly\r\n                self.safety_manager.trigger_safety_protocol()\r\n                break\r\n        \r\n        return execution_plan\r\n    \r\n    def parse_task(self, task_description):\r\n        \"\"\"Parse natural language task into component actions\"\"\"\r\n        # This would involve NLP processing to extract task components\r\n        # For example: \"Walk to the table and pick up the red cup\" \r\n        # would be parsed into walking and grasping subtasks\r\n        subtasks = {}\r\n        \r\n        # Simplified parsing\r\n        if 'walk' in task_description.lower():\r\n            subtasks['right_leg'] = {'type': 'walking', 'destination': 'table'}\r\n        if 'pick' in task_description.lower() or 'grasp' in task_description.lower():\r\n            subtasks['right_arm'] = {'type': 'grasping', 'object': 'red cup'}\r\n            \r\n        return subtasks\r\n    \r\n    def execute_task_component(self, limb, task):\r\n        \"\"\"Execute a specific task component with the specified limb\"\"\"\r\n        if task['type'] == 'walking':\r\n            # Execute walking subtask\r\n            destination = task['destination']\r\n            # Implementation for walking to destination\r\n            pass\r\n        elif task['type'] == 'grasping':\r\n            # Execute grasping subtask\r\n            target_object = task['object']\r\n            # Implementation for grasping object\r\n            pass\r\n        \r\n        return {'status': 'complete', 'limb': limb}\n"})}),"\n",(0,t.jsx)(n.h2,{id:"64-humanoid-control-architectures",children:"6.4 Humanoid Control Architectures"}),"\n",(0,t.jsx)(n.h3,{id:"hierarchical-control-systems",children:"Hierarchical Control Systems"}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots require control systems at multiple levels:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"High-level Planning"}),": Task planning and sequencing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Mid-level Control"}),": Trajectory generation and coordination"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Low-level Control"}),": Joint servo control and feedback"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Safety Systems"}),": Emergency stops and collision avoidance"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"central-pattern-generators-cpgs",children:"Central Pattern Generators (CPGs)"}),"\n",(0,t.jsx)(n.p,{children:"CPGs provide rhythmic patterns for locomotion:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class CentralPatternGenerator:\r\n    def __init__(self, dt=0.01):\r\n        self.dt = dt\r\n        self.oscillators = []\r\n        self.connection_weights = []\r\n        self.outputs = []\r\n        \r\n    def add_oscillator(self, frequency, phase, amplitude):\r\n        """Add an oscillator to the CPG network"""\r\n        oscillator = {\r\n            \'frequency\': frequency,\r\n            \'phase\': phase,\r\n            \'amplitude\': amplitude,\r\n            \'state\': 0.0  # Current state (typically an angle)\r\n        }\r\n        self.oscillators.append(oscillator)\r\n        self.outputs.append(0.0)\r\n        \r\n    def connect_oscillators(self, i, j, weight):\r\n        """Connect two oscillators with specified weight"""\r\n        if len(self.connection_weights) <= i:\r\n            self.connection_weights.extend([[] for _ in range(i - len(self.connection_weights) + 1)])\r\n        while len(self.connection_weights[i]) <= j:\r\n            self.connection_weights[i].append(0.0)\r\n        self.connection_weights[i][j] = weight\r\n        \r\n    def step(self):\r\n        """Update all oscillators for one time step"""\r\n        for i, osc in enumerate(self.oscillators):\r\n            # Update oscillator state based on dynamics\r\n            # This is a simplified version; real CPGs use more complex dynamics\r\n            input_sum = 0.0\r\n            \r\n            # Add inputs from connected oscillators\r\n            if i < len(self.connection_weights):\r\n                for j, weight in enumerate(self.connection_weights[i]):\r\n                    if j < len(self.oscillators):\r\n                        input_sum += weight * np.sin(self.oscillators[j][\'state\'] - osc[\'state\'])\r\n            \r\n            # Update state with frequency and input\r\n            dstate_dt = 2 * np.pi * osc[\'frequency\'] + input_sum\r\n            osc[\'state\'] += dstate_dt * self.dt\r\n            \r\n            # Calculate output\r\n            self.outputs[i] = osc[\'amplitude\'] * np.sin(osc[\'state\'] + osc[\'phase\'])\r\n    \r\n    def get_outputs(self):\r\n        """Get current outputs from all oscillators"""\r\n        return self.outputs.copy()\r\n\r\nclass LocomotionCPG:\r\n    def __init__(self):\r\n        # Initialize CPG for bipedal locomotion\r\n        self.cpg = CentralPatternGenerator(dt=0.01)\r\n        \r\n        # Add oscillators for different joints\r\n        # Left leg oscillators\r\n        self.cpg.add_oscillator(frequency=1.0, phase=0.0, amplitude=1.0)  # Left hip\r\n        self.cpg.add_oscillator(frequency=1.0, phase=np.pi, amplitude=1.0)  # Right hip (anti-phase)\r\n        self.cpg.add_oscillator(frequency=1.0, phase=0.0, amplitude=0.5)   # Left knee\r\n        self.cpg.add_oscillator(frequency=1.0, phase=np.pi, amplitude=0.5)  # Right knee\r\n        \r\n        # Connect oscillators for coordinated movement\r\n        self.cpg.connect_oscillators(0, 1, -1.0)  # Left-right hip coupling\r\n        self.cpg.connect_oscillators(2, 3, -1.0)  # Left-right knee coupling\r\n        self.cpg.connect_oscillators(0, 2, 0.5)   # Hip-knee coupling\r\n        self.cpg.connect_oscillators(1, 3, 0.5)   # Hip-knee coupling (other side)\r\n        \r\n        # Parameters for gait adjustment\r\n        self.step_frequency = 1.0\r\n        self.step_amplitude = 1.0\r\n    \r\n    def update_gait_parameters(self, new_frequency, new_amplitude):\r\n        """Update gait parameters"""\r\n        self.step_frequency = new_frequency\r\n        self.step_amplitude = new_amplitude\r\n        \r\n        # Update oscillator frequencies and amplitudes\r\n        for i, osc in enumerate(self.cpg.oscillators):\r\n            osc[\'frequency\'] = new_frequency\r\n            osc[\'amplitude\'] = new_amplitude * osc[\'amplitude\'] / 1.0  # Maintain relative amplitudes\r\n    \r\n    def get_leg_commands(self):\r\n        """Get joint commands for both legs"""\r\n        outputs = self.cpg.get_outputs()\r\n        \r\n        # Map CPG outputs to actual joint angles\r\n        left_hip_cmd = outputs[0] if len(outputs) > 0 else 0.0\r\n        right_hip_cmd = outputs[1] if len(outputs) > 1 else 0.0\r\n        left_knee_cmd = outputs[2] if len(outputs) > 2 else 0.0\r\n        right_knee_cmd = outputs[3] if len(outputs) > 3 else 0.0\r\n        \r\n        commands = {\r\n            \'left_leg\': [left_hip_cmd, left_knee_cmd],\r\n            \'right_leg\': [right_hip_cmd, right_knee_cmd]\r\n        }\r\n        \r\n        self.cpg.step()  # Update CPG for next time step\r\n        \r\n        return commands\n'})}),"\n",(0,t.jsx)(n.h2,{id:"65-safety-and-emergency-systems",children:"6.5 Safety and Emergency Systems"}),"\n",(0,t.jsx)(n.p,{children:"Safety is paramount in humanoid robot development due to their human-like form factor and interaction potential."}),"\n",(0,t.jsx)(n.h3,{id:"humanoid-safety-manager",children:"Humanoid Safety Manager"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class HumanoidSafetyManager:\r\n    def __init__(self):\r\n        # Safety boundaries\r\n        self.joint_limits = {\r\n            \'hip_pitch\': (-120, 30),\r\n            \'knee\': (0, 135),\r\n            \'ankle_pitch\': (-45, 45),\r\n            \'shoulder_pitch\': (-120, 120),\r\n            \'elbow\': (0, 160)\r\n        }\r\n        \r\n        self.workspace_limits = {\r\n            \'x\': (-1.0, 1.0),\r\n            \'y\': (-1.0, 1.0),\r\n            \'z\': (0.1, 2.0)\r\n        }\r\n        \r\n        self.force_limits = {\r\n            \'gripper_force\': 50.0,  # N\r\n            \'collision_force\': 100.0  # N\r\n        }\r\n        \r\n        # Emergency systems\r\n        self.emergency_stop = False\r\n        self.fall_detected = False\r\n        self.over_force_detected = False\r\n        \r\n        # Safety monitoring\r\n        self.safety_monitoring_active = True\r\n        \r\n    def validate_command(self, joint_angles, cartesian_pos, forces):\r\n        """Validate robot commands against safety limits"""\r\n        safety_violations = []\r\n        \r\n        # Check joint limits\r\n        for joint_name, angle in joint_angles.items():\r\n            if joint_name in self.joint_limits:\r\n                min_limit, max_limit = self.joint_limits[joint_name]\r\n                if angle < min_limit or angle > max_limit:\r\n                    safety_violations.append(f"Joint {joint_name} out of limits: {angle} not in [{min_limit}, {max_limit}]")\r\n        \r\n        # Check workspace limits\r\n        if (cartesian_pos[0] < self.workspace_limits[\'x\'][0] or \r\n            cartesian_pos[0] > self.workspace_limits[\'x\'][1]):\r\n            safety_violations.append(f"X position {cartesian_pos[0]} outside limits")\r\n        \r\n        if (cartesian_pos[1] < self.workspace_limits[\'y\'][0] or \r\n            cartesian_pos[1] > self.workspace_limits[\'y\'][1]):\r\n            safety_violations.append(f"Y position {cartesian_pos[1]} outside limits")\r\n        \r\n        if (cartesian_pos[2] < self.workspace_limits[\'z\'][0] or \r\n            cartesian_pos[2] > self.workspace_limits[\'z\'][1]):\r\n            safety_violations.append(f"Z position {cartesian_pos[2]} outside limits")\r\n        \r\n        # Check force limits\r\n        for force_type, force_value in forces.items():\r\n            if force_type in self.force_limits and force_value > self.force_limits[force_type]:\r\n                safety_violations.append(f"Force limit exceeded for {force_type}: {force_value} > {self.force_limits[force_type]}")\r\n        \r\n        return len(safety_violations) == 0, safety_violations\r\n    \r\n    def monitor_execution(self, robot_state):\r\n        """Monitor robot execution for safety violations"""\r\n        if not self.safety_monitoring_active:\r\n            return True, []\r\n        \r\n        # Check for various safety conditions\r\n        is_safe, violations = self.validate_command(\r\n            robot_state.get(\'joint_angles\', {}),\r\n            robot_state.get(\'cartesian_position\', [0,0,0]),\r\n            robot_state.get(\'applied_forces\', {})\r\n        )\r\n        \r\n        if not is_safe:\r\n            self.trigger_safety_protocol()\r\n            return False, violations\r\n        \r\n        # Check for fall detection\r\n        imu_data = robot_state.get(\'imu_data\', {})\r\n        if self.detect_fall(imu_data):\r\n            self.fall_detected = True\r\n            self.trigger_safety_protocol()\r\n            return False, ["Fall detected"]\r\n        \r\n        return True, []\r\n    \r\n    def detect_fall(self, imu_data):\r\n        """Detect if robot is falling based on IMU data"""\r\n        # Simplified fall detection\r\n        # Check for excessive angular velocity or acceleration\r\n        angular_vel = imu_data.get(\'angular_velocity\', [0,0,0])\r\n        linear_acc = imu_data.get(\'linear_acceleration\', [0,0,0])\r\n        \r\n        # Fall threshold (these values would be tuned based on specific robot)\r\n        ang_vel_threshold = 2.0  # rad/s\r\n        acc_threshold = 15.0  # m/s^2\r\n        \r\n        if np.linalg.norm(angular_vel) > ang_vel_threshold:\r\n            return True\r\n        if np.linalg.norm(linear_acc) > acc_threshold:\r\n            return True\r\n        \r\n        return False\r\n    \r\n    def trigger_safety_protocol(self):\r\n        """Trigger safety protocol"""\r\n        self.emergency_stop = True\r\n        \r\n        # Stop all joint movements\r\n        # Activate joint brakes if available\r\n        # Go to safe position\r\n        # Log safety event\r\n        \r\n        print("SAFETY PROTOCOL TRIGGERED")\r\n    \r\n    def reset_safety(self):\r\n        """Reset safety state after emergency stop"""\r\n        self.emergency_stop = False\r\n        self.fall_detected = False\r\n        self.over_force_detected = False\r\n        \r\n        # Reset other safety flags\r\n        print("Safety system reset")\n'})}),"\n",(0,t.jsx)(n.h2,{id:"66-practical-example-complete-humanoid-system",children:"6.6 Practical Example: Complete Humanoid System"}),"\n",(0,t.jsx)(n.p,{children:"Let's integrate the concepts to create a complete humanoid robot system:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import JointState, Imu\r\nfrom geometry_msgs.msg import Pose, Twist\r\nfrom std_msgs.msg import Float64MultiArray\r\nfrom builtin_interfaces.msg import Duration\r\n\r\nclass HumanoidRobotSystem(Node):\r\n    def __init__(self):\r\n        super().__init__('humanoid_robot_system')\r\n        \r\n        # Initialize control components\r\n        self.safety_manager = HumanoidSafetyManager()\r\n        self.walking_controller = WalkingController()\r\n        self.cpg_locomotion = LocomotionCPG()\r\n        self.grasp_planner = GraspPlanner()\r\n        self.motion_controller = HumanoidMotionController()\r\n        \r\n        # ROS 2 interfaces\r\n        self.joint_state_publisher = self.create_publisher(JointState, '/joint_states', 10)\r\n        self.imu_subscriber = self.create_subscription(Imu, '/imu', self.imu_callback, 10)\r\n        self.command_subscriber = self.create_subscription(Float64MultiArray, '/commands', self.command_callback, 10)\r\n        self.pose_publisher = self.create_publisher(Pose, '/robot_pose', 10)\r\n        \r\n        # Robot state\r\n        self.current_joint_angles = np.zeros(28)  # Example: 28 DOF humanoid\r\n        self.imu_data = {'angular_velocity': [0,0,0], 'linear_acceleration': [0,0,0]}\r\n        self.safety_violations = []\r\n        \r\n        # Control timer\r\n        self.control_timer = self.create_timer(0.01, self.control_loop)  # 100 Hz\r\n        \r\n        self.get_logger().info('Humanoid Robot System initialized')\r\n    \r\n    def imu_callback(self, msg):\r\n        \"\"\"Handle IMU data\"\"\"\r\n        self.imu_data = {\r\n            'angular_velocity': [msg.angular_velocity.x, msg.angular_velocity.y, msg.angular_velocity.z],\r\n            'linear_acceleration': [msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z]\r\n        }\r\n    \r\n    def command_callback(self, msg):\r\n        \"\"\"Handle incoming commands\"\"\"\r\n        # Process and validate commands\r\n        command_data = np.array(msg.data)\r\n        \r\n        # Validate command with safety manager\r\n        robot_state = {\r\n            'joint_angles': dict(enumerate(self.current_joint_angles)),\r\n            'cartesian_position': [0, 0, 0.85],  # Example position\r\n            'applied_forces': {'gripper_force': 0.0},\r\n            'imu_data': self.imu_data\r\n        }\r\n        \r\n        is_safe, violations = self.safety_manager.validate_command(\r\n            robot_state['joint_angles'],\r\n            robot_state['cartesian_position'],\r\n            robot_state['applied_forces']\r\n        )\r\n        \r\n        if is_safe:\r\n            # Execute command\r\n            self.execute_command(command_data)\r\n        else:\r\n            self.safety_violations.extend(violations)\r\n            self.get_logger().warn(f'Safety violations: {violations}')\r\n    \r\n    def execute_command(self, command_data):\r\n        \"\"\"Execute validated command\"\"\"\r\n        # Map command data to joint positions\r\n        if len(command_data) == len(self.current_joint_angles):\r\n            self.current_joint_angles = command_data\r\n        else:\r\n            # Handle command mapping for different formats\r\n            pass\r\n    \r\n    def control_loop(self):\r\n        \"\"\"Main control loop\"\"\"\r\n        # Monitor robot safety\r\n        robot_state = {\r\n            'joint_angles': dict(enumerate(self.current_joint_angles)),\r\n            'cartesian_position': [0, 0, 0.85],\r\n            'applied_forces': {'gripper_force': 0.0},\r\n            'imu_data': self.imu_data\r\n        }\r\n        \r\n        is_safe, violations = self.safety_manager.monitor_execution(robot_state)\r\n        \r\n        if not is_safe:\r\n            self.safety_violations.extend(violations)\r\n            # Emergency stop logic\r\n            self.emergency_stop_sequence()\r\n            return\r\n        \r\n        # Generate joint commands using controllers\r\n        joint_commands = self.generate_joint_commands()\r\n        \r\n        # Publish joint states\r\n        self.publish_joint_states(joint_commands)\r\n        \r\n        # Update CPG for locomotion\r\n        leg_commands = self.cpg_locomotion.get_leg_commands()\r\n        \r\n        # Publish pose estimate\r\n        self.publish_pose_estimate()\r\n    \r\n    def generate_joint_commands(self):\r\n        \"\"\"Generate joint commands based on current tasks\"\"\"\r\n        # This would integrate all control systems\r\n        # For now, return current joint angles\r\n        return self.current_joint_angles\r\n    \r\n    def publish_joint_states(self, joint_positions):\r\n        \"\"\"Publish joint state information\"\"\"\r\n        msg = JointState()\r\n        msg.name = [f'joint_{i}' for i in range(len(joint_positions))]\r\n        msg.position = joint_positions.tolist()\r\n        msg.header.stamp = self.get_clock().now().to_msg()\r\n        \r\n        self.joint_state_publisher.publish(msg)\r\n    \r\n    def publish_pose_estimate(self):\r\n        \"\"\"Publish robot pose estimate\"\"\"\r\n        msg = Pose()\r\n        # Set position based on forward kinematics or estimation\r\n        msg.position.x = 0.0  # Update with actual position\r\n        msg.position.y = 0.0\r\n        msg.position.z = 0.85  # Approximate height\r\n        \r\n        # Set orientation (simplified)\r\n        msg.orientation.w = 1.0  # No rotation initially\r\n        \r\n        self.pose_publisher.publish(msg)\r\n    \r\n    def emergency_stop_sequence(self):\r\n        \"\"\"Execute emergency stop sequence\"\"\"\r\n        self.get_logger().error('EMERGENCY STOP TRIGGERED')\r\n        \r\n        # Stop all motion\r\n        zero_commands = np.zeros_like(self.current_joint_angles)\r\n        self.current_joint_angles = zero_commands\r\n        \r\n        # Go to safe position if possible\r\n        self.go_to_safe_position()\r\n        \r\n        # Log the event\r\n        self.get_logger().info(f'Safety violations logged: {self.safety_violations}')\r\n    \r\n    def go_to_safe_position(self):\r\n        \"\"\"Move robot to predefined safe position\"\"\"\r\n        # Define safe joint configurations\r\n        safe_config = np.zeros_like(self.current_joint_angles)\r\n        # Set safe positions (standing posture)\r\n        safe_config[0::2] = 0.0  # Hip joints to neutral\r\n        safe_config[1::2] = 0.0  # Knee joints to neutral\r\n        # Other joints as appropriate\r\n        \r\n        self.current_joint_angles = safe_config\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    \r\n    # Create and run the humanoid robot system\r\n    humanoid_system = HumanoidRobotSystem()\r\n    \r\n    try:\r\n        rclpy.spin(humanoid_system)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        humanoid_system.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"67-summary",children:"6.7 Summary"}),"\n",(0,t.jsx)(n.p,{children:"This chapter has explored the complex field of humanoid robot development, covering:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The design principles and anthropomorphic considerations in humanoid robotics"}),"\n",(0,t.jsx)(n.li,{children:"The challenges of bipedal locomotion and balance control using ZMP and CPG approaches"}),"\n",(0,t.jsx)(n.li,{children:"The development of dexterous manipulation systems and grasp planning"}),"\n",(0,t.jsx)(n.li,{children:"Multi-limb coordination strategies for complex tasks"}),"\n",(0,t.jsx)(n.li,{children:"Safety systems and emergency protocols for humanoid robots"}),"\n",(0,t.jsx)(n.li,{children:"Integration of all components into a complete humanoid robot system"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robots represent one of the most challenging domains in robotics due to their complexity, but they also offer unique advantages for human interaction and environment compatibility."}),"\n",(0,t.jsx)(n.h2,{id:"68-exercises",children:"6.8 Exercises"}),"\n",(0,t.jsx)(n.h3,{id:"exercise-61-bipedal-walking-simulation",children:"Exercise 6.1: Bipedal Walking Simulation"}),"\n",(0,t.jsx)(n.p,{children:"Create a simulation of bipedal walking using ZMP control. Implement a stable walking pattern for a simplified humanoid model."}),"\n",(0,t.jsx)(n.h3,{id:"exercise-62-grasp-planning-algorithm",children:"Exercise 6.2: Grasp Planning Algorithm"}),"\n",(0,t.jsx)(n.p,{children:"Develop a grasp planning algorithm that identifies optimal grasp points on 3D objects and generates appropriate hand configurations."}),"\n",(0,t.jsx)(n.h3,{id:"exercise-63-multi-limb-coordination",children:"Exercise 6.3: Multi-limb Coordination"}),"\n",(0,t.jsx)(n.p,{children:"Implement a system that coordinates movements between multiple limbs while avoiding conflicts and maintaining balance."}),"\n",(0,t.jsx)(n.h3,{id:"exercise-64-safety-system-integration",children:"Exercise 6.4: Safety System Integration"}),"\n",(0,t.jsx)(n.p,{children:"Design and implement a comprehensive safety system for a humanoid robot, including joint limits, fall detection, and emergency protocols."}),"\n",(0,t.jsx)(n.h3,{id:"exercise-65-complete-humanoid-controller",children:"Exercise 6.5: Complete Humanoid Controller"}),"\n",(0,t.jsx)(n.p,{children:"Build a complete control system that integrates walking, manipulation, and safety functions for a humanoid robot."})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>a});var t=r(6540);const o={},i=t.createContext(o);function s(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);